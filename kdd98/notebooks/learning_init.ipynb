{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer, FunctionTransformer, maxabs_scale\n",
    "\n",
    "from kdd98.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "    # Only use the labels that appear in the data\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    #else:\n",
    "        #print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=Config.get(\"seq_color_map\"))\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"black\" if cm[i, j] < thresh else \"white\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_result_store(file):\n",
    "    result_store = pathlib.Path(\n",
    "        Config.get(\"model_store\"), file)\n",
    "    if result_store.is_file():\n",
    "        with open(result_store, \"rb\") as f:\n",
    "            gridsearch_results = pickle.load(f)\n",
    "    else:\n",
    "        gridsearch_results = {m: {\n",
    "                \"best_estimator\": None,\n",
    "                \"best_score\": -1.0,\n",
    "                \"cv_results\": None\n",
    "            } for m in [\"GBM\", \"RF\", \"GLMnet\", \"NNet\", \"SVM\"]}\n",
    "        with open(result_store, \"wb\") as f:\n",
    "            pickle.dump(gridsearch_results, f)\n",
    "    return gridsearch_results\n",
    "\n",
    "def update_result(model, gridsearch, results_file):\n",
    "    if not model in [\"GBM\", \"RF\", \"GLMnet\", \"NNet\"]:\n",
    "        raise ValueError(\"Invalid model name\")\n",
    "    gridsearch_results = prepare_result_store(results_file)\n",
    "    \n",
    "    previous_score = gridsearch_results[model][\"best_score\"]\n",
    "    if gridsearch.best_score_ > previous_score:\n",
    "        log(\"Storing improved result. Improvement: {}\".format(gridsearch.best_score_-previous_score))\n",
    "        gridsearch_results[model][\"best_estimator\"] = gridsearch.best_estimator_\n",
    "        gridsearch_results[model][\"best_score\"] = gridsearch.best_score_\n",
    "        gridsearch_results[model][\"cv_results\"] = pd.DataFrame(gridsearch.cv_results_)\n",
    "        \n",
    "        file_name =\"gridsearch_{}.pkl\".format(model)\n",
    "        with open(pathlib.Path(Config.get(\"model_store\"),file_name),\"wb\") as f:\n",
    "            pickle.dump(gridsearch, f)\n",
    "        with open(pathlib.Path(Config.get(\"model_store\"),results_file), \"wb\") as f:\n",
    "            pickle.dump(gridsearch_results, f)\n",
    "    else:\n",
    "        log(\"Best params: {}\".format(gridsearch.best_estimator_))\n",
    "        log(\"No improvement over previous search for {}. Not storing results.\".format(model))\n",
    "        \n",
    "def run_experiments(X_train, y_train, config, scoring, cv, refit, results_file):\n",
    "    if not results_file:\n",
    "        results_file = \"gridsearch_results_dict_refit_{}.pkl\".format(refit)\n",
    "    \n",
    "    for m in config:\n",
    "        if config[m][\"run\"]:\n",
    "            params = config[m][\"param_grid\"]\n",
    "            pipe = config[m][\"pipeline\"]\n",
    "            fit_params = config[m][\"fit_params\"]\n",
    "            log(\"Starting gridsearch for {}\".format(m))\n",
    "            gridsearch = RandomizedSearchCV(\n",
    "                pipe,\n",
    "                params,\n",
    "                scoring=scoring,\n",
    "                n_jobs=-1,\n",
    "                cv=10,\n",
    "                pre_dispatch=16, # Limit dispatching to prevent memory overflow\n",
    "                refit=refit,\n",
    "                return_train_score=True,\n",
    "                verbose=10)\n",
    "            if fit_params:\n",
    "                try:\n",
    "                    gridsearch.fit(X_train, y_train, **fit_params)\n",
    "                except Exception as e:\n",
    "                    log(\"Fitting failed for {}. Message: {}\".format(m, e))\n",
    "                    break\n",
    "            else:\n",
    "                try:\n",
    "                    gridsearch.fit(X_train, y_train)\n",
    "                except Exception as e:\n",
    "                    log(\"Fitting failed for {}. Message: {}\".format(m, e))\n",
    "                    break\n",
    "            update_result(m, gridsearch, results_file)\n",
    "        else:\n",
    "            log(\"Skipping {}\".format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Set plot_confusion_matrix(), prepare_result_store(), update_result() and run_experiments()\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
