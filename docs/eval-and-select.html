<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3.5 Model Evaluation and -Selection | Profit maximization for direct marketing campaigns</title>
  <meta name="description" content="Master Thesis submitted in partial fulfillment of the requirements for the degree of Master of Science in Statistics" />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="3.5 Model Evaluation and -Selection | Profit maximization for direct marketing campaigns" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Master Thesis submitted in partial fulfillment of the requirements for the degree of Master of Science in Statistics" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3.5 Model Evaluation and -Selection | Profit maximization for direct marketing campaigns" />
  
  <meta name="twitter:description" content="Master Thesis submitted in partial fulfillment of the requirements for the degree of Master of Science in Statistics" />
  

<meta name="author" content="Florian Hochstrasser" />


<meta name="date" content="2019-06-04" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="methods-prediction.html">
<link rel="next" href="results-and-discussion.html">
<script src="assets/jquery-2.2.3/jquery.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="assets/kePrint-0.0.1/kePrint.js"></script>



<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="task-background.html"><a href="task-background.html"><i class="fa fa-check"></i><b>1.1</b> Task Background</a></li>
<li class="chapter" data-level="1.2" data-path="goal.html"><a href="goal.html"><i class="fa fa-check"></i><b>1.2</b> Goal</a></li>
<li class="chapter" data-level="1.3" data-path="conventions-and-notes.html"><a href="conventions-and-notes.html"><i class="fa fa-check"></i><b>1.3</b> Conventions and Notes</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>2</b> Data</a><ul>
<li class="chapter" data-level="2.1" data-path="general-structure.html"><a href="general-structure.html"><i class="fa fa-check"></i><b>2.1</b> General Structure</a></li>
<li class="chapter" data-level="2.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html"><i class="fa fa-check"></i><b>2.2</b> Exploratory Data Analysis</a><ul>
<li class="chapter" data-level="2.2.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#data-types"><i class="fa fa-check"></i><b>2.2.1</b> Data Types</a></li>
<li class="chapter" data-level="2.2.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#targets"><i class="fa fa-check"></i><b>2.2.2</b> Targets</a></li>
<li class="chapter" data-level="2.2.3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#skewness"><i class="fa fa-check"></i><b>2.2.3</b> Skewness</a></li>
<li class="chapter" data-level="2.2.4" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#correlations"><i class="fa fa-check"></i><b>2.2.4</b> Correlations</a></li>
<li class="chapter" data-level="2.2.5" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#donation-patterns"><i class="fa fa-check"></i><b>2.2.5</b> Donation Patterns</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="experimental-setup-and-methods.html"><a href="experimental-setup-and-methods.html"><i class="fa fa-check"></i><b>3</b> Experimental Setup and Methods</a><ul>
<li class="chapter" data-level="3.1" data-path="tools-used.html"><a href="tools-used.html"><i class="fa fa-check"></i><b>3.1</b> Tools Used</a></li>
<li class="chapter" data-level="3.2" data-path="data-handling.html"><a href="data-handling.html"><i class="fa fa-check"></i><b>3.2</b> Data Handling</a></li>
<li class="chapter" data-level="3.3" data-path="data-preprocessing.html"><a href="data-preprocessing.html"><i class="fa fa-check"></i><b>3.3</b> Data Preprocessing</a><ul>
<li class="chapter" data-level="3.3.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#cleaning"><i class="fa fa-check"></i><b>3.3.1</b> Cleaning</a></li>
<li class="chapter" data-level="3.3.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#methods-feature-engineering"><i class="fa fa-check"></i><b>3.3.2</b> Feature Engineering</a></li>
<li class="chapter" data-level="3.3.3" data-path="data-preprocessing.html"><a href="data-preprocessing.html#imputation"><i class="fa fa-check"></i><b>3.3.3</b> Imputation</a></li>
<li class="chapter" data-level="3.3.4" data-path="data-preprocessing.html"><a href="data-preprocessing.html#methods-feature-selection"><i class="fa fa-check"></i><b>3.3.4</b> Feature Selection</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="methods-prediction.html"><a href="methods-prediction.html"><i class="fa fa-check"></i><b>3.4</b> Prediction</a><ul>
<li class="chapter" data-level="3.4.1" data-path="methods-prediction.html"><a href="methods-prediction.html#optimization-of-alpha"><i class="fa fa-check"></i><b>3.4.1</b> Optimization of <span class="math inline">\(\alpha^*\)</span></a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="eval-and-select.html"><a href="eval-and-select.html"><i class="fa fa-check"></i><b>3.5</b> Model Evaluation and -Selection</a><ul>
<li class="chapter" data-level="3.5.1" data-path="eval-and-select.html"><a href="eval-and-select.html#evaluation"><i class="fa fa-check"></i><b>3.5.1</b> Evaluation</a></li>
<li class="chapter" data-level="3.5.2" data-path="eval-and-select.html"><a href="eval-and-select.html#dealing-with-imbalanced-data"><i class="fa fa-check"></i><b>3.5.2</b> Dealing With Imbalanced Data</a></li>
<li class="chapter" data-level="3.5.3" data-path="eval-and-select.html"><a href="eval-and-select.html#algorithms"><i class="fa fa-check"></i><b>3.5.3</b> Algorithms</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="results-and-discussion.html"><a href="results-and-discussion.html"><i class="fa fa-check"></i><b>4</b> Results and Discussion</a><ul>
<li class="chapter" data-level="4.1" data-path="preprocessing-with-package-kdd98.html"><a href="preprocessing-with-package-kdd98.html"><i class="fa fa-check"></i><b>4.1</b> Preprocessing With Package kdd98</a></li>
<li class="chapter" data-level="4.2" data-path="imputation-1.html"><a href="imputation-1.html"><i class="fa fa-check"></i><b>4.2</b> Imputation</a></li>
<li class="chapter" data-level="4.3" data-path="feature-selection.html"><a href="feature-selection.html"><i class="fa fa-check"></i><b>4.3</b> Feature Selection</a></li>
<li class="chapter" data-level="4.4" data-path="classifiers.html"><a href="classifiers.html"><i class="fa fa-check"></i><b>4.4</b> Classifiers</a></li>
<li class="chapter" data-level="4.5" data-path="regressors.html"><a href="regressors.html"><i class="fa fa-check"></i><b>4.5</b> Regressors</a></li>
<li class="chapter" data-level="4.6" data-path="prediction.html"><a href="prediction.html"><i class="fa fa-check"></i><b>4.6</b> Prediction</a><ul>
<li class="chapter" data-level="4.6.1" data-path="prediction.html"><a href="prediction.html#conditional-prediction-of-the-donation-amount"><i class="fa fa-check"></i><b>4.6.1</b> Conditional Prediction of the Donation Amount</a></li>
<li class="chapter" data-level="4.6.2" data-path="prediction.html"><a href="prediction.html#profit-optimization"><i class="fa fa-check"></i><b>4.6.2</b> Profit Optimization</a></li>
<li class="chapter" data-level="4.6.3" data-path="prediction.html"><a href="prediction.html#final-prediction"><i class="fa fa-check"></i><b>4.6.3</b> Final Prediction</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="conclusions.html"><a href="conclusions.html"><i class="fa fa-check"></i><b>5</b> Conclusions</a><ul>
<li class="chapter" data-level="5.1" data-path="comparison-with-cup-winners.html"><a href="comparison-with-cup-winners.html"><i class="fa fa-check"></i><b>5.1</b> Comparison With Cup Winners</a></li>
<li class="chapter" data-level="5.2" data-path="biggest-problems-remaining.html"><a href="biggest-problems-remaining.html"><i class="fa fa-check"></i><b>5.2</b> Biggest Problems Remaining</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="chapter" data-level="" data-path="appendix-appendix.html"><a href="appendix-appendix.html"><i class="fa fa-check"></i>(APPENDIX) Appendix</a><ul>
<li class="chapter" data-level="5.3" data-path="python-environment.html"><a href="python-environment.html"><i class="fa fa-check"></i><b>5.3</b> Python Environment</a></li>
<li class="chapter" data-level="5.4" data-path="data-set-dictionary.html"><a href="data-set-dictionary.html"><i class="fa fa-check"></i><b>5.4</b> Data Set Dictionary</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Profit maximization for direct marketing campaigns</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="eval-and-select" class="section level2">
<h2><span class="header-section-number">3.5</span> Model Evaluation and -Selection</h2>
<p>During model evaluation, several algorithms were trained and their performance compared using a metric in order to select the best estimator. This was done independently for classifiers (predicting the binary target) and regressors (predicting the continuous target).</p>
<p>One of the powerful tools provided by <code>scikit-learn</code> are pipelines. They enable chaining transforming steps and estimators together. Pipelines were used to re-sample and scale data before model learning. Fitted pipelines can be persisted on disk and then be used later for predictions on other data.</p>
<div id="evaluation" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Evaluation</h3>
<p>Randomized grid search with 10-fold cross-validation (CV) was used for model evaluation. A python dictionary was used to store the best-performing pipeline per algorithm evaluated. The dictionary was persisted to disk and only updated when during a learning iteration, an algorithm produced a better score than the previous best score. This ensured that the best hyperparameter settings and sampling strategies were always retained for each of the algorithms evaluated.</p>
<div id="randomized-grid-search" class="section level4">
<h4><span class="header-section-number">3.5.1.1</span> Randomized Grid Search</h4>
<p>In randomized grid search, distributions for hyperparameter values are specified instead of defining a fixed grid of values to search over (as in grid search cross-validation). The algorithm then runs a defined number of random combinations of the parameters (10 were used). Compared to the usual grid search, this can greatly speed up the learning process because good hyperparameter settings are identified with less iterations.</p>
<p>After one round of learning, the hyperparameter distributions are adjusted before the next iteration as follows: When the best value is found near the limits of the domain, the distribution is shifted in this direction. For values falling inside the domain of the distribution, the distribution is narrowed down towards the found value. This procedure is repeated until the hyperparameters converge.</p>
</div>
<div id="cross-validation" class="section level4">
<h4><span class="header-section-number">3.5.1.2</span> Cross-Validation</h4>
<p>CV splits the training data into several <em>folds</em> of equal size. The algorithm is trained as many times as there are folds, holding back one of the folds at each training step for validation using some specified performance metric and training with the rest of the data. This procedure enables quantification of the generalization error and the calculation of statistics that indicate the variance of the model.</p>
</div>
<div id="performance-metrics" class="section level4">
<h4><span class="header-section-number">3.5.1.3</span> Performance Metrics</h4>
<p>For classification problems, the confusion matrix (see Figure <a href="eval-and-select.html#fig:conf-mat-def">3.3</a>) can be used to construct various performance metrics.</p>

<div class="figure" style="text-align: center"><span id="fig:conf-mat-def"></span>
<img src="figures/conf-mat-def-1.png" alt="Definition of the confusion matrix for a two-class negative / positive (0 / 1) problem. If we predict “1” correctly, it is a true positive (TP), predicting “1” falsely is a false positive (FP). A false negative (FN) occurs when predicting “0” falsely and a true negative (TN) occurs when “0” was predicted correctly." width="40%" />
<p class="caption">
Figure 3.3: Definition of the confusion matrix for a two-class negative / positive (0 / 1) problem. If we predict “1” correctly, it is a <em>true positive</em> (TP), predicting “1” falsely is a <em>false positive</em> (FP). A <em>false negative</em> (FN) occurs when predicting “0” falsely and a <em>true negative</em> (TN) occurs when “0” was predicted correctly.
</p>
</div>
<p>The definitions of some often-used metrics are given below<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a>. The choice of metric depends on the goal of the prediction. Accuracy is often used, but in the case of imbalanced targets, as is the case here, it is not a desirable metric because the majority class dominates the metric.</p>
<p><span class="math display">\[\begin{align*}
\text{Recall / Sensitivity / True Positive Rate TPR} &amp;= \frac{TP}{TP + FN} \\
\text{Specificity / True Negative Rate TNR} &amp;= \frac{TN}{TN+FP} \\ 
\text{Precision / Positive Predictive Value PPV} &amp;= \frac{TP}{TP + FP}\\
\text{Negative Predictive Value NPV} &amp;= \frac{TN}{TN+FN}\\
\text{False Negative Rate FNR} &amp;= \frac{FN}{FN+TP}\\
\text{False Positive Rate FPR} &amp;= \frac{FP}{FP+TN}\\
\text{Accuracy} &amp;= \frac{TP + TN}{TP + FP + FN + TN} \\
\text{F1 score} &amp;= \frac{2TP}{2TP+FP+FN}
\end{align*}\]</span></p>
<p>The goal for our model is to maximize net profit. To achieve this, we have to find a balance between predicting as many TP’s as possible while keeping the number of FN’s and FP’s low. FN’s are kept low by training a model that is good at predicting TP, at the cost of performing worse for TN. Likewise, a low FP means a high rate of TN at the cost of predicting TP.</p>
<p>The metrics that could be used beneficially are F1, recall and precision. One FP costs 0.68 $. Keeping in mind the distribution of profit (Section <a href="exploratory-data-analysis.html#targets">2.2.2</a>), one FN means loosing at least 0.32 $ of possible profit. The expected loss in profit for one FN is approximately 15 $, which means that with each TP, we can balance 22 FP’s on average. Nevertheless, it is beneficial to keep FP as low as possible.</p>
<p>Therefore, <em>F1</em> was chosen as the performance metric for classification. It is the harmonic mean of recall and precision and presents a good compromise, especially for imbalanced data.</p>
<p>For regression, <span class="math inline">\(R^2(y, \hat{y}) = 1- \frac{\sum_{i=1}^n(y_i-\hat{y}_i)^2}{\sum_{i=1}^n(y_i-\bar{y})^2}\)</span> was used. <span class="math inline">\(R^2\)</span> has the drawback of depending on the variance of the data used to fit the model and therefore is different for other data. It was however assumed that because learning and test data have the same generating function, <span class="math inline">\(R^2\)</span> can be used to select a regression model.</p>
</div>
</div>
<div id="dealing-with-imbalanced-data" class="section level3">
<h3><span class="header-section-number">3.5.2</span> Dealing With Imbalanced Data</h3>
<p>Several different approaches were explored:</p>
<ul>
<li>Random oversampling of the minority class</li>
<li>Random undersampling of the majority class</li>
<li>SMOTE (synthetic minority oversampling technique), variant borderline-1</li>
<li>Explicitly specifying class weights</li>
<li>Specifying sample weights using the true donation amount</li>
</ul>
<p>The under-/oversampling algorithms in package <code>imblearn</code> by <span class="citation">Lemaître, Nogueira, and Aridas (<a href="references.html#ref-lemaitre2017imblearn">2017</a>)</span> were used.</p>
</div>
<div id="algorithms" class="section level3">
<h3><span class="header-section-number">3.5.3</span> Algorithms</h3>
<p>A short introduction of each algorithm is given below. For each algorithm, the hyperparameters that were considered during learning are given. The choice of algorithms was made so as to cover a wide range of underlying concepts.</p>
<div id="random-forest" class="section level4">
<h4><span class="header-section-number">3.5.3.1</span> Random Forest</h4>
<p>Random forest (RF), <span class="citation">Breiman (<a href="references.html#ref-breiman2001rf">2001</a>)</span>, belongs to the family of so-called ensemble learners. RF can be used for classification and regression tasks. An ensemble of estimators cast their votes and the prediction is made by the majority vote. In the case of a random forest, the ensemble is made up of decision trees. RF’s are insensitive towards scale differences in the individual features. The input data therefore does not have to be scaled before learning.</p>
<p>The algorithm learns classification and regression trees (CART, see <span class="citation">Breiman et al. (<a href="references.html#ref-breiman1984classification">1984</a>)</span>). For each tree in the forest, a random sample of the available features is drawn with replacement (bagging, or bootstrap aggregating, see <span class="citation">Breiman (<a href="references.html#ref-breiman1996bagging">1996</a>)</span>). By randomly selecting features for each tree, the variance of the ensemble estimator can be reduced. Furthermore, splits are made on a random subset of the features selected to grow the tree. These sources of randomness tend to increase the bias of the forest, yet the decrease in variance due to the averaging through majority vote outweighs the bias increase. <span class="citation">Breiman (<a href="references.html#ref-breiman2001rf">2001</a>)</span> shows that as the forest grows, the generalization error converges almost surely. This means that random forests are insensitive to overfitting.</p>
<p>An interesting aspect of RF is the out of bag (OOB) sample mechanism. It resembles CV by using all trees for prediction in which an example <span class="math inline">\(z_i = (\mathbf{x_i}, y_i)\)</span> did not appear during tree growth. It can be used for early stopping, terminating learning once OOB error stabilises.</p>
<p>Another important feature of RF is the assessment of <em>variable importance</em>. By summing the improvement for each split in every tree per feature, the importance for all features is calculated (see <span class="citation">Friedman, Hastie, and Tibshirani (<a href="references.html#ref-friedman2001elements">2001</a>)</span>).</p>
<p>The <code>RandomForestClassifier</code> and <code>RandomForestRegressor</code> included in <code>scikit-learn</code> were used for learning.</p>
<p><strong>Hyperparameters</strong></p>
<ul>
<li><code>max_depth</code>, <span class="math inline">\(\{1,2,3, ...\}\)</span>: depth of the trees, <span class="math inline">\(2^n\)</span> leafs maximum. Controls the interaction order of features.</li>
<li><code>min_samples_split</code>, <span class="math inline">\(\{2,3,4,...\}\)</span>: Minimum number of samples required for a split.</li>
<li><code>max_features</code>, <span class="math inline">\(\{1, 2, ..., m\}\)</span>: Maximum number of the <span class="math inline">\(m\)</span> features to consider when searching for a split. <span class="citation">Friedman, Hastie, and Tibshirani (<a href="references.html#ref-friedman2001elements">2001</a>)</span> recommend values in <span class="math inline">\(m = \{1, 2, ... \sqrt{m}\}\)</span>, but for high dimensional data with few relevant features, larger <span class="math inline">\(m\)</span> can lead to better results because the probability of including relevant features increases.</li>
<li><code>n_estimators</code>, <span class="math inline">\(\{1, 2, ...\}\)</span>: Number of trees to grow. In combination with early stopping, this can be set to a high value since learning will stop when the loss converges.</li>
<li><code>class_weight</code> <span class="math inline">\(\{\text{balanced}, 1,2,...\}\)</span>: Weights on target classes: “balanced” calculates weights according to class frequencies, integer values specify weight on majority class relative to minority</li>
</ul>
</div>
<div id="gradient-boosting-machine" class="section level4">
<h4><span class="header-section-number">3.5.3.2</span> Gradient Boosting Machine</h4>
<p>Boosting is a method that can be applied to any learning algorithm. The main idea behind boosting is to sequentially train an ensemble of weak learners which on their own are only slightly better than a random decision. The predictions of the individual weak learners are then combined into a majority vote. The idea was first mentioned by <span class="citation">Kearns (<a href="references.html#ref-kearns1988thoughts">1988</a>)</span>. The first algorithm that gained widespread popularity was introduced by <span class="citation">Freund and Schapire (<a href="references.html#ref-freund1997decision">1997</a>)</span> in the form of the algorithm AdaBoost.M1, intended for classification problems.</p>
<p>Gradient boosting machine (GBM) extends on this idea. Like a random forest, GBM learns many trees which form an ensemble. However, trees are learned in an additive manner. At each iteration, the tree that improves the model most (i.e. in the direction of the gradient of the loss function) is added. For this thesis, the package <code>XGBoost</code> by <span class="citation">Chen and Guestrin (<a href="references.html#ref-chen2016xgboost">2016</a>)</span> was used.</p>
<p>Assume we have a data set with <span class="math inline">\(n\)</span> examples and <span class="math inline">\(m\)</span> features: <span class="math inline">\(D = \{\{\mathbf{x_i}, y_i\}\} ( |D| = n, \mathbf{x}_i \in \mathbb{R}^m, y_i \in \mathbb{R})\)</span>. The implementation uses a tree ensemble using <span class="math inline">\(K\)</span> regression trees to predict the outcome for an example in the data by summing up the weights predicted by each tree:</p>
<p><span class="math display" id="eq:gbm-ensemble">\[\begin{equation}
\hat{y}_i = \phi(\mathbf{x_i}) = \sum_{k=1}^K f_k(\mathbf{x_i}), f_k \in F
\tag{3.4}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(F = \{f(\mathbf{x}) = w_{q(x)}\} (q: \mathbb{R}^m \rightarrow T, w \in \mathbb{R}^T)\)</span> is the space of regression trees. <span class="math inline">\(T\)</span> is the number of leaves in a tree, <span class="math inline">\(q\)</span> is the structure of each tree, mapping an example to the corresponding leaf index. Each tree <span class="math inline">\(f_k\)</span> has an independent structure <span class="math inline">\(q\)</span> and weights <span class="math inline">\(w\)</span> at the terminal leafs. An example is classified on each tree in <span class="math inline">\(F\)</span> and the weights of the corresponding leafs are summed up to calculate the final prediciton.</p>
<p>For learning the functions in <span class="math inline">\(F\)</span>, the following loss function is minimized:</p>
<p><span class="math display" id="eq:gbm-loss">\[\begin{equation}
L(\phi) = \sum_{i=1}^n l(y_i, \hat{y_i}) + \sum_k^K \Omega(f_k)
\tag{3.5}
\end{equation}\]</span></p>
<p>Here, <span class="math inline">\(l\)</span> is a differentiable, convex loss function that measures the difference between predictions and true values. Since <span class="math inline">\(l\)</span> is convex, we are guaranteed to find a local minimum. <span class="math inline">\(\Omega(f) = \gamma T + \frac{1}{2}\lambda||w||^2\)</span> is a penalty on the complexity of the trees to counter over-fitting. The algorithm thus features integrated regularization.</p>
<p>Now, at each iteration <span class="math inline">\(t\)</span>, the tree <span class="math inline">\(f_t\)</span> that improves the model most is added. For this, we add <span class="math inline">\(f_t(\mathbf{x_i})\)</span> to the predictions at <span class="math inline">\(t-1\)</span>.</p>
<p><span class="math display" id="eq:gbm-iterate">\[\begin{equation}
L^{(t)} = \sum_{i=1}^n l(y_i, \hat{y_i}^{t-1} + f_t(\mathbf{x_i})) +\Omega(f_t)
\tag{3.6}
\end{equation}\]</span></p>
<p>To find the best <span class="math inline">\(f_t\)</span> to add, the gradients finally come into play. With <span class="math inline">\(g_i\)</span> and <span class="math inline">\(h_i\)</span> the first- and second-order gradient statistics of <span class="math inline">\(l\)</span>, the loss function becomes:</p>
<p><span class="math display" id="eq:gbm-grad">\[\begin{equation}
\tilde{L}^{(t)} = \sum_{i=1}^n l(y_i, \hat{y_i}^{t-1} + g_if_t(\mathbf{x_i}) + h_i f_t^2(\mathbf{x_i})) +\Omega(f_t)
\tag{3.7}
\end{equation}\]</span></p>
<p>A neat feature of XGBoost is it’s ability to deal with missing values. This means that no imputation is necessary during preprocessing, reducing the risk of introducing additional noise through imputation and implicitly allowing to pick up patterns due to the presence of missing values.</p>
<p><strong>Hyperparameters</strong></p>
<ul>
<li><code>learning_rate</code>, <span class="math inline">\([0, 1]\)</span>: <em>Shrinkage</em>, decreases step size for the gradient descent when <span class="math inline">\(\eta &lt; 1.0\)</span>, helping convergence. The number of estimators <span class="math inline">\(f_k\)</span> has to be increased for small learning rates in order for the algorithm to converge.</li>
<li><code>n_iter_no_change</code>, <span class="math inline">\(\{0,1,2,3, ...\}\)</span>: Early stopping. Based on an evaluation set, learning stops when no improvement on the performance metric (misclassification error was chosen) is made for a fixed number of steps.</li>
<li><code>subsample</code>, <span class="math inline">\([0, 1]\)</span>: A random sample from the <span class="math inline">\(n\)</span> examples of size <span class="math inline">\(s, s &lt; n\)</span> is drawn for each iteration, countering overfitting and speeding up learning.</li>
<li><code>colsample_by_tree</code>, <span class="math inline">\([0, 1]\)</span>: A random sample of the <span class="math inline">\(m\)</span> features is drawn for growing each tree.</li>
</ul>
</div>
<div id="glmnet" class="section level4">
<h4><span class="header-section-number">3.5.3.3</span> GLMnet</h4>
<p>The GLMnet is an implementation of a generalized linear model (GLM) with penalized maximum likelihood by <span class="citation">Hastie and Qian (<a href="references.html#ref-hastie2014glmnet">2014</a>)</span>. Regularization is achieved through <span class="math inline">\(L^2\)</span> and <span class="math inline">\(L^1\)</span> penalties (i.e. ridge and the lasso or their combination known as elastic net <span class="citation">Zou and Hastie (<a href="references.html#ref-zou2005regularization">2005</a>)</span>).</p>
<p>For learning, glmnet tries many different <span class="math inline">\(\lambda\)</span> values for a given <span class="math inline">\(\alpha\)</span>. Each <span class="math inline">\(\lambda\)</span> is then evaluated through cross validation. The data (features and target) was transformed to mean zero and unit variance before learning.</p>
<p>For the binary classification task at hand, a logistic regression was performed.
The logistic regression model for a two-class response <span class="math inline">\(G = \{0,1\}\)</span> with target <span class="math inline">\(y_i = I(g_i=1)\)</span>:</p>
<p><span class="math inline">\(P(G=1|X=x) = \frac{e^{\beta_0+\beta^Tx}}{1+e^{\beta_0+\beta^Tx}}\)</span> or, in the log-odds transformation: <span class="math inline">\(log\frac{P(G=1|X=x)}{P(G=0|X=x)}=\beta_0+\beta^Tx\)</span>.</p>
<p>The loss function is:</p>
<p><span class="math display" id="eq:glmnet-logit">\[\begin{equation}
\min_{\beta_0,\beta} \frac{1}{N} \sum_{i=1}^{N} w_i l(y_i,\beta_0+\beta^T x_i) + \lambda\left[(1-\alpha)||\beta||_2^2/2 + \alpha ||\beta||_1\right]
\tag{3.8}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(w_i\)</span> are individual sample weights, <span class="math inline">\(l()\)</span> the (negative) log-likelihood of the parameters <span class="math inline">\(\mathbf{\beta}\)</span> given the data, <span class="math inline">\(\lambda\)</span> the amount of penalization and <span class="math inline">\(\alpha \in [0,1]\)</span> the elastic net parameter, for <span class="math inline">\(\alpha=0\)</span> pure ridge and for <span class="math inline">\(\alpha=1\)</span> pure lasso.</p>
<p>For the regression task, a gaussian family model was used, having loss function:</p>
<p><span class="math display" id="eq:glmnet-gaussian">\[\begin{equation}
\min_{(\beta_0, \beta) \in \mathbb{R}^{p+1}}\frac{1}{2N} \sum_{i=1}^N (y_i -\beta_0-x_i^T \beta)^2+\lambda \left[ (1-\alpha)||\beta||_2^2/2 + \alpha||\beta||_1\right]
\tag{3.9}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(l()\)</span> the (negative) log-likelihood of the parameters <span class="math inline">\(\mathbf{\beta}\)</span> given the data, <span class="math inline">\(\lambda\)</span> the amount of penalization and <span class="math inline">\(\alpha \in [0,1]\)</span> the elastic net parameter, for <span class="math inline">\(\alpha=0\)</span> pure ridge and for <span class="math inline">\(\alpha=1\)</span> pure lasso.</p>
<p><strong>Hyperparameters</strong></p>
<ul>
<li><code>n_splits</code>, <span class="math inline">\(\{3,4,5, ...\}\)</span>: Number of CV-splits. Typical values are 3, 5 and 10.</li>
<li><span class="math inline">\(\alpha\)</span>, <span class="math inline">\([0, 1]\)</span>: parametrizes the elastic net. For <span class="math inline">\(\alpha = 0\)</span> pure ridge, for <span class="math inline">\(\alpha = 1\)</span> pure lasso.</li>
<li><code>scoring</code>: Scoring method for cross-validation (log-loss, classification error, accuracy, precision, recall, average precision, roc-auc)</li>
</ul>
</div>
<div id="multilayer-perceptron" class="section level4">
<h4><span class="header-section-number">3.5.3.4</span> Multilayer Perceptron</h4>
<p>The multilayer perceptron (MLP) is a so-called feedforward neural network. The term feedforward means that information flows from the input layer through intermediary steps and then to the output.</p>
<p>The goal is to approximate the function <span class="math inline">\(f^*\)</span>. For a classifier, <span class="math inline">\(y = f^*(\mathbf{x})\)</span> maps an example <span class="math inline">\(\mathbf{x}\)</span> to a category <span class="math inline">\(y\)</span>. A feedforward network defines a mapping <span class="math inline">\(\mathbf{y}=f(\mathbf{x}, \mathbf{w})\)</span> and learns the weights <span class="math inline">\(w\)</span> by approximating the function <span class="math inline">\(f\)</span>.</p>
<p>The MLP consists of at least three layers: an input layer, an arbitrary number of hidden layers and an output layer. For a binary classification problem on a dataset with <span class="math inline">\(n\)</span> examples and <span class="math inline">\(m\)</span> features <span class="math inline">\(D = \{\{\mathbf{x_i}, y_i\}\}, \mathbf{x}_i \in \mathbb{R}^m, y_i \in \{0,1\}, i = 1...n\)</span>, the input layer has <span class="math inline">\(m\)</span> units, the output layer has <span class="math inline">\(1\)</span> unit. The hidden layers each have an arbitrary number of units.</p>
<p>Each unit, except for the input layer, consists of a perceptron, which is in effect a linear model with some non-linear activation function applied:</p>
<p><span class="math display" id="eq:perceptron">\[\begin{equation}
y = \phi(\mathbf{w}^T\mathbf{x}+b)
\tag{3.10}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\phi\)</span> is a non-linear activation function, <span class="math inline">\(\mathbf{w}\)</span> is the vector of weights, <span class="math inline">\(\mathbf{x}\)</span> is the vector of inputs and b is the bias. For <span class="math inline">\(\phi\)</span>, typical functions are the hyperbolic tangens <span class="math inline">\(tanh(\cdot)\)</span>, the logistic sigmoid <span class="math inline">\(\sigma(x) = \frac{1}{1+e^{-x}}\)</span>, or, more recently, the rectified linear unit <span class="math inline">\(relu(x) = max(0,x)\)</span> proposed by <span class="citation">Hahnloser et al. (<a href="references.html#ref-hahnloser2000digital">2000</a>)</span>.</p>
<p>For learning, the weights in each unit are initialized first (typically random, near-zero). Then, the training examples are fed to the network sequentially. For each example, the prediction error is calculated using a loss function, which is typically the negative log-likelihood.</p>
<p>Then, the partial derivatives of the loss function with respect to the weights are computed for each unit and the parameters updated using stochastic gradient descent through backpropagation.</p>
<p>For this thesis, the scikit-learn implementation <code>sklearn.neural_network.MLPClassifier</code> was used. The network topology was determined by trying several variants. Best results were achieved with a network featuring two hidden layers with 50 and 10 hidden units, respectively.</p>
<p>The complete network is a chain of functions, for the network trained here, it is:
<span class="math display">\[\begin{equation}
\mathbf{y} = \phi^{(3)}(\mathbf{W}^{(3)T} \mathbf{\phi}^{(2)}(\mathbf{W}^{(2)T} \mathbf{\phi}^{(1)}(\mathbf{W}^{(1)T} \mathbf{x} + \mathbf{b}^{(1)}) + \mathbf{b}^{(2)}) + \mathbf{b}^{(3)})
\end{equation}\]</span>
where <span class="math inline">\(\mathbf{x}\)</span> is the vector of input features, <span class="math inline">\(\mathbf{y}\)</span> is the vector of predicted outputs, <span class="math inline">\(\mathbf{W}^{(1)}, \mathbf{W}^{(2)}, \mathbf{W}^{(3)}\)</span> are the weight matrices for each layer and <span class="math inline">\(\mathbf{b}^{(1)}, \mathbf{b}^{(2)}, \mathbf{b}^{(3)}\)</span> are the bias vectors for each layer and <span class="math inline">\(\mathbf{\phi}^{(1)}, \mathbf{\phi}^{(2)}, \mathbf{\phi}^{(3)}\)</span> are the sets of perceptrons in the corresponding layer.</p>

<div class="figure" style="text-align: center"><span id="fig:mlp-graph"></span>
<img src="figures/preprocessing/mlp-structure.png" alt="Neural network topology used. Two hidden layers \(\mathbf{h^{(1)}, h^{(2)}}\) are contained. \(\mathbf{b^{(2)}, b^{(3)}}\) and \(\mathbf{b^{(4)}}\) are the bias vectors for the respective layers." width="60%" />
<p class="caption">
Figure 3.4: Neural network topology used. Two hidden layers <span class="math inline">\(\mathbf{h^{(1)}, h^{(2)}}\)</span> are contained. <span class="math inline">\(\mathbf{b^{(2)}, b^{(3)}}\)</span> and <span class="math inline">\(\mathbf{b^{(4)}}\)</span> are the bias vectors for the respective layers.
</p>
</div>
</div>
<div id="support-vector-machine" class="section level4">
<h4><span class="header-section-number">3.5.3.5</span> Support Vector Machine</h4>
<p>(Boser et al.,1992; Vapnik,1998; Schölkopf et al.,1999a)</p>
<p><span class="math display" id="eq:svm-model">\[\begin{equation}
y(\mathbf{x}, \mathbf{w}) = \sum_{i=1}^n w_i K(\mathbf{x},\mathbf{x_i}) + w_0
\tag{3.11}
\end{equation}\]</span></p>
</div>
<div id="bayesian-ridge-regression" class="section level4">
<h4><span class="header-section-number">3.5.3.6</span> Bayesian Ridge Regression</h4>
<p>Bayesian Ridge Regression (BR) can be seen as a Bayesian approach to <span class="math inline">\(l_2\)</span> regularization. The scikit-learn implementation was used. The algorithm implements <span class="citation">Tipping (<a href="references.html#ref-tipping2001sparse">2001</a>)</span>. We have the linear regression model for ordinary linear regression (see <span class="citation">Albert (<a href="references.html#ref-albert2009bayesian">2009</a>)</span>), where we assume <span class="math inline">\(\{y_i\}\)</span> are conditionally independent, <span class="math inline">\(var(y_i|\mathbf{\beta},\mathbf{X}) = \sigma^2\)</span> and the errors <span class="math inline">\(\epsilon_i = y_i - E(y_i|\beta,X) \sim\)</span> iid with mean 0 and variance <span class="math inline">\(\sigma^2\)</span>:</p>
<p><span class="math display" id="eq:bayesian-linear-model">\[\begin{equation}
p(\mathbf{y}|\mathbf{\beta},\sigma^2,\mathbf{X}) \sim N_n(\mathbf{X \beta},\sigma^2 \mathbf{I})
\tag{3.12}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\mathbf{y}\)</span> is the vector of observed target values, <span class="math inline">\(X\)</span> is the design matrix with <span class="math inline">\(\mathbf{x}_1, ... \mathbf{x}_n\)</span> examples and <span class="math inline">\(N_k(\mu, A)\)</span> is a multivariate normal distribution of dimension <span class="math inline">\(k\)</span> with mean <span class="math inline">\(\mu\)</span> and variance-covariance matrix <span class="math inline">\(A\)</span>.</p>
<p>We now put the following prior distribution on the coefficients <span class="math inline">\(\beta\)</span>:</p>
<p><span class="math display" id="eq:br-prior">\[\begin{equation}
p(\beta|\lambda) = N(\beta|0, \lambda^{-1}\mathbf(I))
\tag{3.13}
\end{equation}\]</span></p>
<p>For <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\lambda\)</span>, gamma distributions are chosen as prior distributions. The parameters of the gamma distributions <span class="math inline">\(\alpha_1, \alpha_2, \lambda_1\)</span> and <span class="math inline">\(\lambda_2\)</span> are chosen non-informative and are set to <span class="math inline">\(\alpha_1 = \alpha_2 = \lambda_1\)</span> = <span class="math inline">\(\lambda_2 = 10^{-6}\)</span>.</p>

</div>
</div>
</div>
<!-- </div> -->
<div class="footnotes">
<hr />
<ol start="12">
<li id="fn12"><p>taken from <a href="https://en.wikipedia.org/wiki/Confusion_matrix">https://en.wikipedia.org/wiki/Confusion_matrix</a>, accessed on 28.05.2019<a href="eval-and-select.html#fnref12" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="methods-prediction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="results-and-discussion.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": true,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["Master_Thesis_Florian_Hochstrasser.pdf"],
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
