{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer, FunctionTransformer, maxabs_scale\n",
    "\n",
    "from kdd98.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config.set(\"model_store\", \"/data/home/datarian/OneDrive/unine/Master_Thesis/ma-thesis-report/models\")\n",
    "Config.set(\"data_dir\", \"/data/home/datarian/OneDrive/unine/Master_Thesis/ma-thesis-report/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/home/datarian/OneDrive/unine/Master_Thesis/ma-thesis-report/models'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Config.get(\"model_store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None):\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=Config.get(\"seq_color_map\"))\n",
    "    if normalize:\n",
    "        ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           ylabel='True',\n",
    "           xlabel='Predicted')\n",
    "    if title:\n",
    "        ax.set(title=title)\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"black\" if cm[i, j] < thresh else \"white\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_result_store(file):\n",
    "    result_store = pathlib.Path(\n",
    "        Config.get(\"model_store\"), file)\n",
    "    if result_store.is_file():\n",
    "        with open(result_store, \"rb\") as f:\n",
    "            gridsearch_results = pickle.load(f)\n",
    "    else:\n",
    "        gridsearch_results = {m: {\n",
    "                \"best_estimator\": None,\n",
    "                \"best_score\": -1.0,\n",
    "                \"best_params\": None,\n",
    "                \"cv_results\": None\n",
    "            } for m in [\"GBM\", \"RF\", \"GLMnet\", \"NNet\", \"SVM\"]}\n",
    "        with open(result_store, \"wb\") as f:\n",
    "            pickle.dump(gridsearch_results, f)\n",
    "    return gridsearch_results\n",
    "\n",
    "def update_result(model, gridsearch, results_file, ignore_score=False):\n",
    "    if not model in [\"GBM\", \"RF\", \"GLMnet\", \"NNet\", \"SVM\"]:\n",
    "        raise ValueError(\"Invalid model name\")\n",
    "    gridsearch_results = prepare_result_store(results_file)\n",
    "    \n",
    "    previous_score = gridsearch_results[model][\"best_score\"]\n",
    "    if gridsearch.best_score_ > previous_score or ignore_score:\n",
    "        log(\"Storing result. Score change: {}\".format(gridsearch.best_score_-previous_score))\n",
    "        log(\"Best params: {}\".format(gridsearch.best_params_))\n",
    "        gridsearch_results[model][\"best_estimator\"] = gridsearch.best_estimator_\n",
    "        gridsearch_results[model][\"best_params\"] = gridsearch.best_params_\n",
    "        gridsearch_results[model][\"best_score\"] = gridsearch.best_score_\n",
    "        gridsearch_results[model][\"cv_results\"] = pd.DataFrame(gridsearch.cv_results_)\n",
    "        with open(pathlib.Path(Config.get(\"model_store\"),results_file), \"wb\") as f:\n",
    "            pickle.dump(gridsearch_results, f)\n",
    "    else:\n",
    "        log(\"Best params: {}\".format(gridsearch.best_params_))\n",
    "        log(\"No improvement over previous search for {}. Not storing results.\".format(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(pathlib.Path(Config.get(\"model_store\"), \"classifiers_refit_f1.pkl\"), \"rb\") as f:\n",
    "    clfs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_estimator': Pipeline(memory=None,\n",
       "      steps=[('scaler', PowerTransformer(copy=True, method='yeo-johnson', standardize=True)), ('sampler', BorderlineSMOTE(k_neighbors=5, kind='borderline-1', m_neighbors=10, n_jobs=1,\n",
       "         random_state=42, sampling_strategy=0.9507610378684456)), ('classifier', MLPClassifier(activation='relu', alpha=0.5...=True, solver='adam', tol=0.0001,\n",
       "        validation_fraction=0.1, verbose=False, warm_start=False))]),\n",
       " 'best_score': 0.13082304508831785,\n",
       " 'best_params': {'classifier__alpha': 0.5,\n",
       "  'classifier__hidden_layer_sizes': (28, 28),\n",
       "  'classifier__learning_rate_init': 0.07925436438616416,\n",
       "  'sampler__sampling_strategy': 0.9507610378684456},\n",
       " 'cv_results':    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       " 0      74.163042      6.649175         0.425421        0.126196   \n",
       " 1      78.847192      7.775132         0.325821        0.125901   \n",
       " 2      80.535002      9.309415         0.381549        0.119747   \n",
       " 3      80.491182      9.230287         0.419594        0.115255   \n",
       " 4      78.527753     15.386248         0.340990        0.109276   \n",
       " 5      71.103309      5.894336         0.297214        0.119432   \n",
       " 6      79.435397     12.268315         0.349970        0.078247   \n",
       " 7      83.984653     11.850513         0.329724        0.123710   \n",
       " 8      83.697282     11.386941         0.302871        0.088148   \n",
       " 9      68.025786      7.326710         0.256345        0.070589   \n",
       " \n",
       "   param_classifier__alpha param_classifier__hidden_layer_sizes  \\\n",
       " 0                     0.5                             (28, 28)   \n",
       " 1                     0.5                             (28, 28)   \n",
       " 2                     0.5                               (100,)   \n",
       " 3                     0.5                             (30, 16)   \n",
       " 4                     0.5                             (30, 16)   \n",
       " 5                     0.5                             (28, 28)   \n",
       " 6                     0.5                             (28, 28)   \n",
       " 7                     0.5                              (50, 6)   \n",
       " 8                     0.5                               (100,)   \n",
       " 9                     0.5                             (30, 16)   \n",
       " \n",
       "   param_classifier__learning_rate_init param_sampler__sampling_strategy  \\\n",
       " 0                            0.0761204                         0.939786   \n",
       " 1                             0.084174                          0.90053   \n",
       " 2                             0.077579                         0.917089   \n",
       " 3                            0.0832086                         0.971846   \n",
       " 4                            0.0807161                         0.927998   \n",
       " 5                            0.0770508                         0.996799   \n",
       " 6                            0.0792544                         0.950761   \n",
       " 7                            0.0802984                         0.970723   \n",
       " 8                            0.0778863                         0.958124   \n",
       " 9                            0.0843201                         0.932064   \n",
       " \n",
       "                                               params  split0_test_auc  ...  \\\n",
       " 0  {'classifier__alpha': 0.5, 'classifier__hidden...         0.568337  ...   \n",
       " 1  {'classifier__alpha': 0.5, 'classifier__hidden...         0.573766  ...   \n",
       " 2  {'classifier__alpha': 0.5, 'classifier__hidden...         0.570791  ...   \n",
       " 3  {'classifier__alpha': 0.5, 'classifier__hidden...         0.571691  ...   \n",
       " 4  {'classifier__alpha': 0.5, 'classifier__hidden...         0.573853  ...   \n",
       " 5  {'classifier__alpha': 0.5, 'classifier__hidden...         0.571260  ...   \n",
       " 6  {'classifier__alpha': 0.5, 'classifier__hidden...         0.581645  ...   \n",
       " 7  {'classifier__alpha': 0.5, 'classifier__hidden...         0.568184  ...   \n",
       " 8  {'classifier__alpha': 0.5, 'classifier__hidden...         0.575988  ...   \n",
       " 9  {'classifier__alpha': 0.5, 'classifier__hidden...         0.570947  ...   \n",
       " \n",
       "    split2_train_f1  split3_train_f1  split4_train_f1  split5_train_f1  \\\n",
       " 0         0.131070         0.135062         0.131078         0.131726   \n",
       " 1         0.132642         0.135010         0.130874         0.132640   \n",
       " 2         0.134629         0.130665         0.128946         0.131688   \n",
       " 3         0.128999         0.130747         0.133875         0.129750   \n",
       " 4         0.130073         0.129860         0.130812         0.137260   \n",
       " 5         0.131100         0.133807         0.130490         0.131983   \n",
       " 6         0.128588         0.127814         0.134094         0.130415   \n",
       " 7         0.127334         0.131966         0.000000         0.123402   \n",
       " 8         0.125827         0.129373         0.130165         0.128385   \n",
       " 9         0.132976         0.128897         0.131073         0.135343   \n",
       " \n",
       "    split6_train_f1  split7_train_f1  split8_train_f1  split9_train_f1  \\\n",
       " 0         0.130811         0.130158         0.132974         0.130090   \n",
       " 1         0.133225         0.132156         0.136442         0.134069   \n",
       " 2         0.130814         0.132540         0.132110         0.130693   \n",
       " 3         0.131312         0.132078         0.128964         0.128927   \n",
       " 4         0.132901         0.128870         0.130079         0.133380   \n",
       " 5         0.126954         0.129590         0.128487         0.128210   \n",
       " 6         0.128380         0.130489         0.130114         0.130621   \n",
       " 7         0.130023         0.000000         0.127178         0.129566   \n",
       " 8         0.128179         0.131529         0.130546         0.133561   \n",
       " 9         0.130000         0.130265         0.131053         0.134191   \n",
       " \n",
       "    mean_train_f1  std_train_f1  \n",
       " 0       0.131973      0.001999  \n",
       " 1       0.134014      0.002046  \n",
       " 2       0.132165      0.002293  \n",
       " 3       0.130439      0.001517  \n",
       " 4       0.131685      0.002303  \n",
       " 5       0.130397      0.001981  \n",
       " 6       0.130476      0.002047  \n",
       " 7       0.103909      0.052060  \n",
       " 8       0.130203      0.002326  \n",
       " 9       0.131473      0.001948  \n",
       " \n",
       " [10 rows x 84 columns]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs[\"NNet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(X_train, y_train, config, scoring, splits, refit):\n",
    "    results_file = \"classifiers_refit_{}.pkl\".format(refit)\n",
    "    \n",
    "    for m in config:\n",
    "        if config[m][\"run\"]:\n",
    "            params = config[m][\"param_grid\"]\n",
    "            pipe = config[m][\"pipeline\"]\n",
    "            fit_params = config[m][\"fit_params\"]\n",
    "            log(\"Starting gridsearch for {}\".format(m))\n",
    "            cv = StratifiedKFold(n_splits=splits, random_state=Config.get(\"random_seed\"))\n",
    "            gridsearch = RandomizedSearchCV(\n",
    "                pipe,\n",
    "                params,\n",
    "                scoring=scoring,\n",
    "                n_jobs=-1,\n",
    "                cv=cv,\n",
    "                pre_dispatch=4, # Limit dispatching to prevent memory overflow\n",
    "                refit=refit,\n",
    "                return_train_score=True,\n",
    "                verbose=10)\n",
    "            if fit_params:\n",
    "                try:\n",
    "                    gridsearch.fit(X_train, y_train, **fit_params)\n",
    "                except Exception as e:\n",
    "                    log(\"Fitting failed for {}. Message: {}\".format(m, e))\n",
    "                    break\n",
    "            else:\n",
    "                try:\n",
    "                    gridsearch.fit(X_train, y_train)\n",
    "                except Exception as e:\n",
    "                    log(\"Fitting failed for {}. Message: {}\".format(m, e))\n",
    "                    break\n",
    "            print(\"Fitting done. Best score: {}, best parameters: {}\".format(gridsearch.best_score_, gridsearch.best_params_))\n",
    "            update_result(m, gridsearch, results_file)\n",
    "        else:\n",
    "            log(\"Skipping {}\".format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Set plot_confusion_matrix(), prepare_result_store(), update_result() and run_experiments()\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
