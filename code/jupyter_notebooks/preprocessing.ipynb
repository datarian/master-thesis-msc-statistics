{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "This notebook contains all code for the preprocessing of the KDD Cup 98 datasets.\n",
    "* Splits into learning and test\n",
    "* Learns the transformation pipeline on the learning dataset for future use\n",
    "* Prepares the data for model fitting\n",
    "\n",
    "This will be done with scikit-learn's transforming framework in order to ensure all transformations are applied identically on training, test and validation datasets.\n",
    "\n",
    "\n",
    "The transformations are 'learned' on the training dataset and then applied to the test dataset and new data later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "os.chdir(\"../\") # Change to project root\n",
    "from util.data_loader import KDD98DataLoader\n",
    "from kdd98.transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plto config\n",
    "%matplotlib inline\n",
    "sns.set(color_codes=True)\n",
    "sns.set_style('ticks')\n",
    "plt.rcParams['figure.figsize'] = [40, 40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the learning dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set working directory to main code folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2 # automatically reloads modules\n",
    "lrn = dl.KDD98DataLoader(\"cup98LRN.txt\")\n",
    "learning_raw = lrn.get_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into training- and test dataset\n",
    "\n",
    "Before applying any transformations, the dataset will be split 80/20 into a learning and test set.\n",
    "\n",
    "Let's first look at feature TARGET_B, which describes whether a person has donated or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.949241\n",
       "1    0.050759\n",
       "Name: TARGET_B, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_raw.TARGET_B.value_counts(normalize=True) # 5 % of recipients have donated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to preserve this ratio in the split datasets. scikit-learn provides a class for achieving this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import App\n",
    "seed = App.config(\"random_seed\")\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, train_size=0.8, random_state=seed)\n",
    "for learn_index, test_index in splitter.split(learning_raw, learning_raw.TARGET_B.astype('int')):\n",
    "    l_i = learn_index\n",
    "    t_i = test_index\n",
    "    kdd_learn = learning_raw.iloc[learn_index]\n",
    "    kdd_test = learning_raw.iloc[test_index]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, check that the two sets are really disjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(kdd_learn.index).intersection(kdd_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the frequencies of the donors in the sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.949246\n",
       "1    0.050754\n",
       "Name: TARGET_B, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kdd_learn['TARGET_B'].value_counts()/len(kdd_learn.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.949222\n",
       "1    0.050778\n",
       "Name: TARGET_B, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kdd_test['TARGET_B'].value_counts()/len(kdd_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating features and label\n",
    "\n",
    "First, we separate the features from the labels. We will also remove the label \"TARGET_B\", which is an indicator variable for donors that is no longer of interest\n",
    "\n",
    "**All preprocessing is performed on *kdd_learn_feat***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdd_learn_feat = kdd_learn.drop(['TARGET_B', 'TARGET_D'],axis=1)\n",
    "kdd_learn_label = kdd_learn['TARGET_D'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring strategies for specific feature types\n",
    "\n",
    "* Noisy data: Correction of data entry / formatting errors\n",
    "    - These errors must be corrected without excluding the records in question\n",
    "* Missing data: Has to be inferred from known values\n",
    "    - (e.g., mean, median, mode, a modeled value).\n",
    "    - One exception to this rule is the attributes containing 99.5 percent or more missings. These are to be dropped\n",
    "* Sparse data: Events actually represented in given data make only a very small subset of the event space are to be dropped\n",
    "* Constant values are to be dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant and Sparse Features\n",
    "\n",
    "Features where only one value is present and those where the majority is empty are to be dropped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADATE_5     0.0\n",
       "ADATE_15    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = learning_raw.var()\n",
    "v[v <= 1e-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFA_2R has elements: [L]\n",
      "Categories (1, object): [L]\n"
     ]
    }
   ],
   "source": [
    "for f in kdd_learn_feat.columns:\n",
    "    if len(kdd_learn_feat[f].unique()) == 1:\n",
    "        print(f+\" has elements: \"+ str(kdd_learn_feat[f].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = []\n",
    "for column in learning:\n",
    "    top_freq = learning[column].value_counts(normalize=True).iloc[0]\n",
    "    if top_freq > 0.995:\n",
    "        sparse_features.append(column)\n",
    "        print(column+\" has a top frequency of: \" + str(top_freq))\n",
    "        print(learning[column].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{9604.0}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(kdd_learn_feat.ADATE_5.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{9504.0}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(kdd_learn_feat.ADATE_15.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean features\n",
    "\n",
    "From the dataset dictionary, a number of boolean features could be identified. These are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MAILCODE', 'NOEXCH', 'RECINHSE', 'RECP3', 'RECPGVG', 'AGEFLAG', 'HOMEOWNR', 'MAJOR', 'COLLECT1', 'VETERANS', 'BIBLE', 'CATLG', 'HOMEE', 'PETS', 'CDPLAY', 'STEREO', 'PCOWNERS', 'PHOTO', 'CRAFTS', 'FISHER', 'GARDENIN', 'BOATS', 'WALKER', 'KIDSTUFF', 'CARDS', 'PLATES', 'PEPSTRFL', 'TARGET_B', 'HPHONE_D']\n"
     ]
    }
   ],
   "source": [
    "print(dl.boolean_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now deal with these features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(categories=\"auto\"))\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remaining object features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = learning_raw.select_dtypes(include='object').columns\n",
    "print(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in objects:\n",
    "    print(f+\": \"+learning_raw[f].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are two types:\n",
    "\n",
    "* ZIP: Malformed zip codes. Some have a dash at the end, which has to be removed.\n",
    "* Multibyte values. These can be extracted into separate features bytewise. However, this is done in feature extraction later on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Pipeline\n",
    "\n",
    "It is now time to construct the preprocessing pipeline. A set of transforming operations is concatenated to a sequence of operations. This pipeline is the learned on the learning dataset. All transformations to the learning dataset will then later be applied to the test dataset and to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feats = list(kdd_learn_feat.select_dtypes(include=np.number).columns)\n",
    "categorical_feats = list(kdd_learn_feat.select_dtypes(include=np.number).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformers = ColumnTransformer([\n",
    "    (\"bool_x_bl\",\n",
    "    BooleanFeatureRecode(value_map={'true': 'X', 'false': ' '}),\n",
    "    ['PEPSTRFL', 'NOEXCH', 'MAJOR', 'RECINHSE', 'RECP3', 'RECPGVG', 'RECSWEEP']\n",
    "    ),\n",
    "    (\"bool_y_n\",\n",
    "     BooleanFeatureRecode(value_map={'true': 'Y', 'false': 'N'}),\n",
    "     ['COLLECT1', 'VETERANS', 'BIBLE', 'CATLG', 'HOMEE', 'PETS','CDPLAY', 'STEREO',\n",
    "      'PCOWNERS', 'PHOTO', 'CRAFTS', 'FISHER', 'GARDENIN',  'BOATS', 'WALKER', 'KIDSTUFF',\n",
    "      'CARDS', 'PLATES']\n",
    "    ),\n",
    "    (\"bool_e_i\",\n",
    "     BooleanFeatureRecode(value_map={'true': \"E\", 'false': 'I'}),\n",
    "     ['AGEFLAG']\n",
    "    ),\n",
    "    (\"bool_h_u\",\n",
    "     BooleanFeatureRecode(value_map={'true': \"H\", 'false': 'U'}),\n",
    "     ['HOMEOWNR']),\n",
    "    (\"bool_b_bl\",\n",
    "     BooleanFeatureRecode(value_map={'true': 'B', 'false': ' '}),\n",
    "     ['MAILCODE']\n",
    "    ),\n",
    "    (\"bool_1_0\",\n",
    "     BooleanFeatureRecode(value_map={'true': '1', 'false': '0'}),\n",
    "     ['HPHONE_D']\n",
    "    ),\n",
    "    (\"zipcode_trim\",\n",
    "     ZipCodeFormatter(),\n",
    "     ['ZIP']\n",
    "    ),\n",
    "    (\"numerical_features\",\n",
    "     numerical_pipe,\n",
    "     numerical_feats\n",
    "    ),\n",
    "    (\"categorical_features\",\n",
    "     categorical_pipe,\n",
    "     categorical_feats\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interests and donations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = learning_raw.loc[:,dl.interest_features+[\"TARGET_D\"]].fillna(0)\n",
    "interests = pd.melt(data,value_vars=dl.interest_features, value_name=\"Interest\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features with constant values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_raw.nunique(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual feature properties\n",
    "\n",
    "Value range, distribution, outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations\n",
    "\n",
    "-> Product moment covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the correlation matrix\n",
    "corr = learning_raw.drop(['TARGET_B','TARGET_D'],axis=1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the heatmap\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.8, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target variable (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.catplot(x=\"WEALTH2\", y=\"TARGET_D\", hue=\"MAJOR\",\n",
    "            kind=\"violin\", inner=\"stick\", split=True,\n",
    "            palette=\"pastel\", data=learning);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"CLUSTER\", y=\"TARGET_D\", kind=\"box\", data=learning);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.distplot(learning.loc[learning.TARGET_D > 0.0, 'TARGET_D'], bins=50, kde=False, rug=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_census = [\"POP901\", \"POP902\", \"POP903\", \"POP90C1\", \"POP90C2\", \"POP90C3\", \"POP90C4\", \"POP90C5\", \"ETH1\", \"ETH2\", \"ETH3\", \"ETH4\", \"ETH5\", \"ETH6\", \"ETH7\", \"ETH8\", \"ETH9\", \"ETH10\", \"ETH11\", \"ETH12\", \"ETH13\", \"ETH14\", \"ETH15\", \"ETH16\", \"AGE901\", \"AGE902\", \"AGE903\", \"AGE904\", \"AGE905\", \"AGE906\", \"AGE907\", \"CHIL1\", \"CHIL2\", \"CHIL3\", \"AGEC1\", \"AGEC2\", \"AGEC3\", \"AGEC4\", \"AGEC5\", \"AGEC6\", \"AGEC7\", \"CHILC1\", \"CHILC2\", \"CHILC3\", \"CHILC4\", \"CHILC5\", \"HHAGE1\", \"HHAGE2\", \"HHAGE3\", \"HHN1\", \"HHN2\", \"HHN3\", \"HHN4\", \"HHN5\", \"HHN6\", \"MARR1\", \"MARR2\", \"MARR3\", \"MARR4\", \"HHP1\", \"HHP2\", \"DW1\", \"DW2\", \"DW3\", \"DW4\", \"DW5\", \"DW6\", \"DW7\", \"DW8\", \"DW9\", \"HV1\", \"HV2\", \"HV3\", \"HV4\", \"HU1\", \"HU2\", \"HU3\", \"HU4\", \"HU5\", \"HHD1\", \"HHD2\", \"HHD3\", \"HHD4\", \"HHD5\", \"HHD6\", \"HHD7\", \"HHD8\", \"HHD9\", \"HHD10\", \"HHD11\", \"HHD12\", \"ETHC1\", \"ETHC2\", \"ETHC3\", \"ETHC4\", \"ETHC5\", \"ETHC6\", \"HVP1\", \"HVP2\", \"HVP3\", \"HVP4\", \"HVP5\", \"HVP6\", \"HUR1\", \"HUR2\", \"RHP1\", \"RHP2\", \"RHP3\", \"RHP4\", \"HUPA1\", \"HUPA2\", \"HUPA3\", \"HUPA4\", \"HUPA5\", \"HUPA6\", \"HUPA7\", \"RP1\", \"RP2\", \"RP3\", \"RP4\", \"MSA\", \"ADI\", \"DMA\", \"IC1\", \"IC2\", \"IC3\", \"IC4\", \"IC5\", \"IC6\", \"IC7\", \"IC8\", \"IC9\", \"IC10\", \"IC11\", \"IC12\", \"IC13\", \"IC14\", \"IC15\", \"IC16\", \"IC17\", \"IC18\", \"IC19\", \"IC20\", \"IC21\", \"IC22\", \"IC23\", \"HHAS1\", \"HHAS2\", \"HHAS3\", \"HHAS4\", \"MC1\", \"MC2\", \"MC3\", \"TPE1\", \"TPE2\", \"TPE3\", \"TPE4\", \"TPE5\", \"TPE6\", \"TPE7\", \"TPE8\", \"TPE9\", \"PEC1\", \"PEC2\", \"TPE10\", \"TPE11\", \"TPE12\", \"TPE13\", \"LFC1\", \"LFC2\", \"LFC3\", \"LFC4\", \"LFC5\", \"LFC6\", \"LFC7\", \"LFC8\", \"LFC9\", \"LFC10\", \"OCC1\", \"OCC2\", \"OCC3\", \"OCC4\", \"OCC5\", \"OCC6\", \"OCC7\", \"OCC8\", \"OCC9\", \"OCC10\", \"OCC11\", \"OCC12\", \"OCC13\", \"EIC1\", \"EIC2\", \"EIC3\", \"EIC4\", \"EIC5\", \"EIC6\", \"EIC7\", \"EIC8\", \"EIC9\", \"EIC10\", \"EIC11\", \"EIC12\", \"EIC13\", \"EIC14\", \"EIC15\", \"EIC16\", \"OEDC1\", \"OEDC2\", \"OEDC3\", \"OEDC4\", \"OEDC5\", \"OEDC6\", \"OEDC7\", \"EC1\", \"EC2\", \"EC3\", \"EC4\", \"EC5\", \"EC6\", \"EC7\", \"EC8\", \"SEC1\", \"SEC2\", \"SEC3\", \"SEC4\", \"SEC5\", \"AFC1\", \"AFC2\", \"AFC3\", \"AFC4\", \"AFC5\", \"AFC6\", \"VC1\", \"VC2\", \"VC3\", \"VC4\", \"ANC1\", \"ANC2\", \"ANC3\", \"ANC4\", \"ANC5\", \"ANC6\", \"ANC7\", \"ANC8\", \"ANC9\", \"ANC10\", \"ANC11\", \"ANC12\", \"ANC13\", \"ANC14\", \"ANC15\", \"POBC1\", \"POBC2\", \"LSC1\", \"LSC2\", \"LSC3\", \"LSC4\", \"VOC1\", \"VOC2\", \"VOC3\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC5\", \"HC6\", \"HC7\", \"HC8\", \"HC9\", \"HC10\", \"HC11\", \"HC12\", \"HC13\", \"HC14\", \"HC15\", \"HC16\", \"HC17\", \"HC18\", \"HC19\", \"HC20\", \"HC21\", \"MHUC1\", \"MHUC2\", \"AC1\", \"AC2\"]\n",
    "len(us_census)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "Meant to reduce dimensionality by selecting only features that are 'interesting enough' to be considered in order to boost performance of calculations / improve accuracy of the estimator\n",
    "- By variance threshold\n",
    "- Recursive Feature Elimination by Cross-Validation\n",
    "- L1-based feature selection (Logistic Regression, Lasso, SVM)\n",
    "- Tree-based feature selection\n",
    "\n",
    "See [scikit-learn: feature selection](http://scikit-learn.org/stable/modules/feature_selection.html#feature-selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing constant features (zero variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in learning.columns:\n",
    "        if len(learning[column].unique()) == 1:\n",
    "            print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = []\n",
    "for column in learning:\n",
    "    top_freq = learning[column].value_counts(normalize=True).iloc[0]\n",
    "    if top_freq > 0.995:\n",
    "        sparse_features.append(column)\n",
    "        print(column+\" has a top frequency of: \" + str(top_freq))\n",
    "        print(learning[column].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "All explanatory fields have to be numerical for the subsequent operations with scikit-learn. Here, the necessary feature extractions are performed.\n",
    "\n",
    "See [scikit-learn: feature extraction](http://scikit-learn.org/stable/modules/feature_extraction.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbolic_features = []\n",
    "symbolic_features.append(tds.SymbolicFeatureSpreader(\n",
    "    \"DOMAIN\", [\"U\", \"S\"])) #Urbanicity, SocioEconomicStatus\n",
    "# RFA_2 is already spread out\n",
    "for i in range(3, 25):\n",
    "    feature = \"_\".join([\"RFA\", str(i)])\n",
    "    symbolic_features.append(tds.SymbolicFeatureSpreader(\n",
    "        feature, [\"R\", \"F\", \"A\"])) # Recency, Frequency, Amount\n",
    "\n",
    "spread_multibyte = pd.DataFrame(index=learning_raw.index)\n",
    "for f in symbolic_features:\n",
    "    f.set_tidy_dataset_ref(learning_raw)\n",
    "    spread_multibyte = pd.concat([spread_multibyte,f.spread(inplace=False)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spread_multibyte.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "A first look at important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = learning.drop([\"TARGET_B\",\"TARGET_D\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp = 3\n",
    "pca = decomposition.PCA(n_components = n_comp)\n",
    "pca.fit(X)\n",
    "result = pd.DataFrame(pca.transform(X), columns=[\"PCA%i\" % i for i in range(n_comp)], index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cProfile\n",
    "domain_spreader = tds.SymbolicFieldToDummies(learning,\"RFA_24\",[\"Recency\", \"Frequency\", \"Amount\"])\n",
    "cProfile.run('domain_spreader.spread()', sort='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "os.getcwd()\n",
    "proj_dir = os.path.split(os.getcwd())[0]\n",
    "if proj_dir not in sys.path:\n",
    "    sys.path.append(proj_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eda.tidy_dataset as tds\n",
    "tidy = tds.TidyDataset(\"cup98LRN.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = tidy.get_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spreader = tds.SymbolicFieldToDummies(\n",
    "    raw, \"RFA_24\", [\"Recency\", \"Frequency\", \"Amount\"])\n",
    "spreader.spread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
