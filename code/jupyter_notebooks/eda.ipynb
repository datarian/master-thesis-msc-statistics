{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "This notebook contains all code for the prelimiatory analysis of the KDD Cup 98 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "os.chdir(\"../\")\n",
    "import util.data_loader as dl\n",
    "from kdd98.transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "plt.rcParams['figure.figsize'] = (20, 20)\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "# seaborn config\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "sns.set_style('ticks')\n",
    "sns.axes_style({'spines.right': False,\n",
    "                'axes.spines.top': False})\n",
    "sns.set_palette('viridis')\n",
    "\n",
    "# figures:\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \"../../\"\n",
    "CHAPTER_ID = \"eda\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"figures\", CHAPTER_ID)\n",
    "\n",
    "if not os.path.exists(IMAGES_PATH):\n",
    "    os.makedirs(IMAGES_PATH)\n",
    "\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the learning dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set working directory to main code folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2  # automatically reloads modules\n",
    "data_loader = dl.KDD98DataLoader(\"cup98LRN.txt\")\n",
    "learning = data_loader.get_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first, general look at the data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 95412 entries, 95515 to 185114\n",
      "Columns: 478 entries, ODATEDW to GEOCODE2\n",
      "dtypes: category(24), float64(51), int64(302), object(101)\n",
      "memory usage: 333.4+ MB\n"
     ]
    }
   ],
   "source": [
    "learning.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODATEDW</th>\n",
       "      <th>OSOURCE</th>\n",
       "      <th>TCODE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>MAILCODE</th>\n",
       "      <th>PVASTATE</th>\n",
       "      <th>DOB</th>\n",
       "      <th>NOEXCH</th>\n",
       "      <th>RECINHSE</th>\n",
       "      <th>...</th>\n",
       "      <th>TARGET_D</th>\n",
       "      <th>HPHONE_D</th>\n",
       "      <th>RFA_2R</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>RFA_2A</th>\n",
       "      <th>MDMAUD_R</th>\n",
       "      <th>MDMAUD_F</th>\n",
       "      <th>MDMAUD_A</th>\n",
       "      <th>CLUSTER2</th>\n",
       "      <th>GEOCODE2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONTROLN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95515</th>\n",
       "      <td>8901</td>\n",
       "      <td>GRI</td>\n",
       "      <td>0</td>\n",
       "      <td>IL</td>\n",
       "      <td>61081</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3712</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>39.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148535</th>\n",
       "      <td>9401</td>\n",
       "      <td>BOA</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>91326</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5202</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>2</td>\n",
       "      <td>G</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15078</th>\n",
       "      <td>9001</td>\n",
       "      <td>AMH</td>\n",
       "      <td>1</td>\n",
       "      <td>NC</td>\n",
       "      <td>27017</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>60.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172556</th>\n",
       "      <td>8701</td>\n",
       "      <td>BRY</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>95953</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2801</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>41.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7112</th>\n",
       "      <td>8601</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>FL</td>\n",
       "      <td>33176</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>26.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 478 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ODATEDW OSOURCE TCODE STATE    ZIP MAILCODE PVASTATE   DOB NOEXCH  \\\n",
       "CONTROLN                                                                     \n",
       "95515       8901     GRI     0    IL  61081                    3712      0   \n",
       "148535      9401     BOA     1    CA  91326                    5202      0   \n",
       "15078       9001     AMH     1    NC  27017                       0      0   \n",
       "172556      8701     BRY     0    CA  95953                    2801      0   \n",
       "7112        8601             0    FL  33176                    2001      0   \n",
       "\n",
       "         RECINHSE   ...    TARGET_D HPHONE_D RFA_2R RFA_2F RFA_2A  MDMAUD_R  \\\n",
       "CONTROLN            ...                                                       \n",
       "95515               ...         0.0        0      L      4      E         X   \n",
       "148535              ...         0.0        0      L      2      G         X   \n",
       "15078               ...         0.0        1      L      4      E         X   \n",
       "172556              ...         0.0        1      L      4      E         X   \n",
       "7112            X   ...         0.0        1      L      2      F         X   \n",
       "\n",
       "         MDMAUD_F MDMAUD_A CLUSTER2 GEOCODE2  \n",
       "CONTROLN                                      \n",
       "95515           X        X     39.0        C  \n",
       "148535          X        X      1.0        A  \n",
       "15078           X        X     60.0        C  \n",
       "172556          X        X     41.0        C  \n",
       "7112            X        X     26.0        A  \n",
       "\n",
       "[5 rows x 478 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AGE', 'NUMCHLD', 'INCOME', 'HIT', 'MBCRAFT', 'MBGARDEN', 'MBBOOKS',\n",
      "       'MBCOLECT', 'MAGFAML', 'MAGFEM',\n",
      "       ...\n",
      "       'MAXRAMNT', 'MAXRDATE', 'LASTGIFT', 'LASTDATE', 'FISTDATE', 'NEXTDATE',\n",
      "       'TIMELAG', 'AVGGIFT', 'TARGET_D', 'CLUSTER2'],\n",
      "      dtype='object', length=353)\n"
     ]
    }
   ],
   "source": [
    "numerical = learning.select_dtypes(include=np.number).columns\n",
    "print(numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features\n",
    "\n",
    "Categories were defined on import of the csv data. The categories were identified in the dataset dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TCODE', 'STATE', 'PVASTATE', 'DOMAIN', 'CLUSTER', 'CHILD03', 'CHILD07',\n",
      "       'CHILD12', 'CHILD18', 'GENDER', 'WEALTH1', 'DATASRCE', 'SOLP3', 'SOLIH',\n",
      "       'WEALTH2', 'GEOCODE', 'LIFESRC', 'RFA_2R', 'RFA_2F', 'RFA_2A',\n",
      "       'MDMAUD_R', 'MDMAUD_F', 'MDMAUD_A', 'GEOCODE2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "categories = learning.select_dtypes(include='category').columns\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCODE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>PVASTATE</th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>CHILD03</th>\n",
       "      <th>CHILD07</th>\n",
       "      <th>CHILD12</th>\n",
       "      <th>CHILD18</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>...</th>\n",
       "      <th>WEALTH2</th>\n",
       "      <th>GEOCODE</th>\n",
       "      <th>LIFESRC</th>\n",
       "      <th>RFA_2R</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>RFA_2A</th>\n",
       "      <th>MDMAUD_R</th>\n",
       "      <th>MDMAUD_F</th>\n",
       "      <th>MDMAUD_A</th>\n",
       "      <th>GEOCODE2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>...</td>\n",
       "      <td>51589</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>55</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td></td>\n",
       "      <td>R2</td>\n",
       "      <td>40</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>40917</td>\n",
       "      <td>17343</td>\n",
       "      <td>93954</td>\n",
       "      <td>13623</td>\n",
       "      <td>3979</td>\n",
       "      <td>94266</td>\n",
       "      <td>93846</td>\n",
       "      <td>93601</td>\n",
       "      <td>92565</td>\n",
       "      <td>51277</td>\n",
       "      <td>...</td>\n",
       "      <td>6523</td>\n",
       "      <td>80168</td>\n",
       "      <td>54032</td>\n",
       "      <td>95412</td>\n",
       "      <td>47675</td>\n",
       "      <td>46964</td>\n",
       "      <td>95118</td>\n",
       "      <td>95118</td>\n",
       "      <td>95118</td>\n",
       "      <td>34484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TCODE  STATE PVASTATE DOMAIN CLUSTER CHILD03 CHILD07 CHILD12 CHILD18  \\\n",
       "count   95412  95412    95412  95412   95412   95412   95412   95412   95412   \n",
       "unique     55     57        3     17      54       4       4       4       4   \n",
       "top         0     CA              R2      40                                   \n",
       "freq    40917  17343    93954  13623    3979   94266   93846   93601   92565   \n",
       "\n",
       "       GENDER   ...    WEALTH2 GEOCODE LIFESRC RFA_2R RFA_2F RFA_2A MDMAUD_R  \\\n",
       "count   95412   ...      51589   95412   95412  95412  95412  95412    95412   \n",
       "unique      7   ...         10       8       4      1      4      4        5   \n",
       "top         F   ...          9                      L      1      F        X   \n",
       "freq    51277   ...       6523   80168   54032  95412  47675  46964    95118   \n",
       "\n",
       "       MDMAUD_F MDMAUD_A GEOCODE2  \n",
       "count     95412    95412    95280  \n",
       "unique        4        5        5  \n",
       "top           X        X        A  \n",
       "freq      95118    95118    34484  \n",
       "\n",
       "[4 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning.loc[:, categories].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Features\n",
    "\n",
    "These features have mixed datatypes and are encoded as strings. This hints at noisy data and features that will have to be transformed before becoming usable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ODATEDW', 'OSOURCE', 'ZIP', 'MAILCODE', 'DOB', 'NOEXCH', 'RECINHSE',\n",
      "       'RECP3', 'RECPGVG', 'RECSWEEP',\n",
      "       ...\n",
      "       'RDATE_17', 'RDATE_18', 'RDATE_19', 'RDATE_20', 'RDATE_21', 'RDATE_22',\n",
      "       'RDATE_23', 'RDATE_24', 'TARGET_B', 'HPHONE_D'],\n",
      "      dtype='object', length=101)\n"
     ]
    }
   ],
   "source": [
    "objects = learning.select_dtypes(include='object').columns\n",
    "print(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODATEDW</th>\n",
       "      <th>OSOURCE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>MAILCODE</th>\n",
       "      <th>DOB</th>\n",
       "      <th>NOEXCH</th>\n",
       "      <th>RECINHSE</th>\n",
       "      <th>RECP3</th>\n",
       "      <th>RECPGVG</th>\n",
       "      <th>RECSWEEP</th>\n",
       "      <th>...</th>\n",
       "      <th>RDATE_17</th>\n",
       "      <th>RDATE_18</th>\n",
       "      <th>RDATE_19</th>\n",
       "      <th>RDATE_20</th>\n",
       "      <th>RDATE_21</th>\n",
       "      <th>RDATE_22</th>\n",
       "      <th>RDATE_23</th>\n",
       "      <th>RDATE_24</th>\n",
       "      <th>TARGET_B</th>\n",
       "      <th>HPHONE_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>...</td>\n",
       "      <td>9401</td>\n",
       "      <td>19778</td>\n",
       "      <td>15877</td>\n",
       "      <td>7888</td>\n",
       "      <td>9513</td>\n",
       "      <td>20873</td>\n",
       "      <td>7859</td>\n",
       "      <td>17738</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>54</td>\n",
       "      <td>896</td>\n",
       "      <td>19938</td>\n",
       "      <td>2</td>\n",
       "      <td>947</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>9501</td>\n",
       "      <td>MBC</td>\n",
       "      <td>85351</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>9503</td>\n",
       "      <td>9501</td>\n",
       "      <td>9412</td>\n",
       "      <td>9412</td>\n",
       "      <td>9411</td>\n",
       "      <td>9409</td>\n",
       "      <td>9408</td>\n",
       "      <td>9407</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>15358</td>\n",
       "      <td>4539</td>\n",
       "      <td>61</td>\n",
       "      <td>94013</td>\n",
       "      <td>23661</td>\n",
       "      <td>95085</td>\n",
       "      <td>88709</td>\n",
       "      <td>93395</td>\n",
       "      <td>95298</td>\n",
       "      <td>93795</td>\n",
       "      <td>...</td>\n",
       "      <td>4729</td>\n",
       "      <td>10665</td>\n",
       "      <td>12504</td>\n",
       "      <td>4516</td>\n",
       "      <td>5006</td>\n",
       "      <td>11195</td>\n",
       "      <td>4522</td>\n",
       "      <td>7861</td>\n",
       "      <td>90569</td>\n",
       "      <td>47765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ODATEDW OSOURCE    ZIP MAILCODE    DOB NOEXCH RECINHSE  RECP3 RECPGVG  \\\n",
       "count    95412   95412  95412    95412  95412  95412    95412  95412   95412   \n",
       "unique      54     896  19938        2    947      3        2      2       2   \n",
       "top       9501     MBC  85351               0      0                           \n",
       "freq     15358    4539     61    94013  23661  95085    88709  93395   95298   \n",
       "\n",
       "       RECSWEEP   ...    RDATE_17 RDATE_18 RDATE_19 RDATE_20 RDATE_21  \\\n",
       "count     95412   ...        9401    19778    15877     7888     9513   \n",
       "unique        2   ...          11       14       13       10       12   \n",
       "top               ...        9503     9501     9412     9412     9411   \n",
       "freq      93795   ...        4729    10665    12504     4516     5006   \n",
       "\n",
       "       RDATE_22 RDATE_23 RDATE_24 TARGET_B HPHONE_D  \n",
       "count     20873     7859    17738    95412    95412  \n",
       "unique       13       17       14        2        2  \n",
       "top        9409     9408     9407        0        1  \n",
       "freq      11195     4522     7861    90569    47765  \n",
       "\n",
       "[4 rows x 101 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning.loc[:, objects].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date features\n",
    "These are imported as strings and will have to be transformed later on to become useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LASTDATE</th>\n",
       "      <th>MINRDATE</th>\n",
       "      <th>MAXRDATE</th>\n",
       "      <th>FISTDATE</th>\n",
       "      <th>NEXTDATE</th>\n",
       "      <th>MAXADATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>95412.000000</td>\n",
       "      <td>95412.000000</td>\n",
       "      <td>95412.000000</td>\n",
       "      <td>95412.000000</td>\n",
       "      <td>85439.000000</td>\n",
       "      <td>95412.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9548.100365</td>\n",
       "      <td>9252.650998</td>\n",
       "      <td>9441.860426</td>\n",
       "      <td>9135.651648</td>\n",
       "      <td>9151.022917</td>\n",
       "      <td>9701.631409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>49.235664</td>\n",
       "      <td>267.511838</td>\n",
       "      <td>172.870471</td>\n",
       "      <td>320.394019</td>\n",
       "      <td>294.257260</td>\n",
       "      <td>5.752179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9503.000000</td>\n",
       "      <td>7506.000000</td>\n",
       "      <td>7510.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7211.000000</td>\n",
       "      <td>9608.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9509.000000</td>\n",
       "      <td>9101.000000</td>\n",
       "      <td>9409.000000</td>\n",
       "      <td>8810.000000</td>\n",
       "      <td>8903.000000</td>\n",
       "      <td>9702.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9512.000000</td>\n",
       "      <td>9309.000000</td>\n",
       "      <td>9506.000000</td>\n",
       "      <td>9201.000000</td>\n",
       "      <td>9204.000000</td>\n",
       "      <td>9702.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9602.000000</td>\n",
       "      <td>9504.000000</td>\n",
       "      <td>9512.000000</td>\n",
       "      <td>9409.000000</td>\n",
       "      <td>9409.000000</td>\n",
       "      <td>9702.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9702.000000</td>\n",
       "      <td>9702.000000</td>\n",
       "      <td>9702.000000</td>\n",
       "      <td>9603.000000</td>\n",
       "      <td>9702.000000</td>\n",
       "      <td>9702.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LASTDATE      MINRDATE      MAXRDATE      FISTDATE      NEXTDATE  \\\n",
       "count  95412.000000  95412.000000  95412.000000  95412.000000  85439.000000   \n",
       "mean    9548.100365   9252.650998   9441.860426   9135.651648   9151.022917   \n",
       "std       49.235664    267.511838    172.870471    320.394019    294.257260   \n",
       "min     9503.000000   7506.000000   7510.000000      0.000000   7211.000000   \n",
       "25%     9509.000000   9101.000000   9409.000000   8810.000000   8903.000000   \n",
       "50%     9512.000000   9309.000000   9506.000000   9201.000000   9204.000000   \n",
       "75%     9602.000000   9504.000000   9512.000000   9409.000000   9409.000000   \n",
       "max     9702.000000   9702.000000   9702.000000   9603.000000   9702.000000   \n",
       "\n",
       "           MAXADATE  \n",
       "count  95412.000000  \n",
       "mean    9701.631409  \n",
       "std        5.752179  \n",
       "min     9608.000000  \n",
       "25%     9702.000000  \n",
       "50%     9702.000000  \n",
       "75%     9702.000000  \n",
       "max     9702.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = learning.loc[:, dl.date_features]\n",
    "dates.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "\n",
    "We will leverage scikit-learn's transformer classes, and add our own custom transformers. This might on first glance look as a tedious way to clean data. However, it will be very powerful later on. The transformer's parameters are actually hyperparameters in model selection. This means that a grid-search can be employed to evaluate several different strategies for i.e. imputation of missing values, cutoff thresholds for sparse features and so on and find the best preprocessing steps.\n",
    "\n",
    "sklearn doc:\n",
    "\n",
    "* http://scikit-learn.org/dev/modules/generated/sklearn.compose.ColumnTransformer.html\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "#from category_encoders.hashing import HashingEncoder  # Use custom edits in local file instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean features\n",
    "\n",
    "For these, we will convert the values specified as True and False as per the dataset dictionary into 1.0 and 0.0 respectively. Furthermore, input errors are also being treated. In the end, these features will be of dtype float64, having {1.0, 0.0 and NaN} as values.\n",
    "\n",
    "For features that either have a value representing True or are empty (as specified in the dataset dictionary), all empty cells will be considered False. For features specifically denoting True and False values, these will be coded appropriately and empty cells set to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MAILCODE', 'NOEXCH', 'RECSWEEP', 'RECINHSE', 'RECP3', 'RECPGVG', 'AGEFLAG', 'HOMEOWNR', 'MAJOR', 'COLLECT1', 'BIBLE', 'CATLG', 'HOMEE', 'PETS', 'CDPLAY', 'STEREO', 'PCOWNERS', 'PHOTO', 'CRAFTS', 'FISHER', 'GARDENIN', 'BOATS', 'WALKER', 'KIDSTUFF', 'CARDS', 'PLATES', 'PEPSTRFL', 'TARGET_B', 'HPHONE_D', 'VETERANS']\n"
     ]
    }
   ],
   "source": [
    "print(dl.boolean_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "bool_transformers = ColumnTransformer([\n",
    "    (\"bool_x_bl\",\n",
    "     BooleanFeatureRecode(value_map={'true': 'X', 'false': ' '}, correct_noisy=False),\n",
    "     ['PEPSTRFL', 'NOEXCH', 'MAJOR', 'RECINHSE', 'RECP3', 'RECPGVG', 'RECSWEEP']\n",
    "     ),\n",
    "    (\"bool_y_n\",\n",
    "     BooleanFeatureRecode(value_map={'true': 'Y', 'false': 'N'}, correct_noisy=False),\n",
    "     ['COLLECT1', 'VETERANS', 'BIBLE', 'CATLG', 'HOMEE', 'PETS', 'CDPLAY', 'STEREO',\n",
    "      'PCOWNERS', 'PHOTO', 'CRAFTS', 'FISHER', 'GARDENIN',  'BOATS', 'WALKER', 'KIDSTUFF',\n",
    "      'CARDS', 'PLATES']\n",
    "     ),\n",
    "    (\"bool_e_i\",\n",
    "     BooleanFeatureRecode(value_map={'true': \"E\", 'false': 'I'}, correct_noisy=False),\n",
    "     ['AGEFLAG']\n",
    "     ),\n",
    "    (\"bool_h_u\",\n",
    "     BooleanFeatureRecode(value_map={'true': \"H\", 'false': 'U'}, correct_noisy=False),\n",
    "     ['HOMEOWNR']),\n",
    "    (\"bool_b_bl\",\n",
    "     BooleanFeatureRecode(value_map={'true': 'B', 'false': ' '}, correct_noisy=False),\n",
    "     ['MAILCODE']\n",
    "     ),\n",
    "    (\"bool_1_0\",\n",
    "     BooleanFeatureRecode(value_map={'true': '1', 'false': '0'}, correct_noisy=False),\n",
    "     ['HPHONE_D', 'TARGET_B']\n",
    "     )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "booleans = bool_transformers.fit_transform(learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_feature_names = [n[n.find('__')+2:]\n",
    "                 for n in bool_transformers.get_feature_names()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bools = pd.DataFrame(data=booleans, columns=bool_feature_names,\n",
    "                     index=learning.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PEPSTRFL</th>\n",
       "      <th>NOEXCH</th>\n",
       "      <th>MAJOR</th>\n",
       "      <th>RECINHSE</th>\n",
       "      <th>RECP3</th>\n",
       "      <th>RECPGVG</th>\n",
       "      <th>RECSWEEP</th>\n",
       "      <th>COLLECT1</th>\n",
       "      <th>VETERANS</th>\n",
       "      <th>BIBLE</th>\n",
       "      <th>...</th>\n",
       "      <th>BOATS</th>\n",
       "      <th>WALKER</th>\n",
       "      <th>KIDSTUFF</th>\n",
       "      <th>CARDS</th>\n",
       "      <th>PLATES</th>\n",
       "      <th>AGEFLAG</th>\n",
       "      <th>HOMEOWNR</th>\n",
       "      <th>MAILCODE</th>\n",
       "      <th>HPHONE_D</th>\n",
       "      <th>TARGET_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>95412.000000</td>\n",
       "      <td>95412.000000</td>\n",
       "      <td>95412.000000</td>\n",
       "      <td>95412.000000</td>\n",
       "      <td>95412.000000</td>\n",
       "      <td>95412.000000</td>\n",
       "      <td>95412.000000</td>\n",
       "      <td>5202.0</td>\n",
       "      <td>10426.0</td>\n",
       "      <td>8871.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>10501.0</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>65864.000000</td>\n",
       "      <td>73184.000000</td>\n",
       "      <td>95412.000000</td>\n",
       "      <td>95412.000000</td>\n",
       "      <td>95412.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.474458</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>0.070253</td>\n",
       "      <td>0.021140</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.016948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.870643</td>\n",
       "      <td>0.715375</td>\n",
       "      <td>0.014663</td>\n",
       "      <td>0.500618</td>\n",
       "      <td>0.050759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499350</td>\n",
       "      <td>0.057816</td>\n",
       "      <td>0.055425</td>\n",
       "      <td>0.255575</td>\n",
       "      <td>0.143851</td>\n",
       "      <td>0.034546</td>\n",
       "      <td>0.129076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335598</td>\n",
       "      <td>0.451239</td>\n",
       "      <td>0.120199</td>\n",
       "      <td>0.500002</td>\n",
       "      <td>0.219506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PEPSTRFL        NOEXCH         MAJOR      RECINHSE         RECP3  \\\n",
       "count  95412.000000  95412.000000  95412.000000  95412.000000  95412.000000   \n",
       "mean       0.474458      0.003354      0.003081      0.070253      0.021140   \n",
       "std        0.499350      0.057816      0.055425      0.255575      0.143851   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "            RECPGVG      RECSWEEP  COLLECT1  VETERANS   BIBLE      ...       \\\n",
       "count  95412.000000  95412.000000    5202.0   10426.0  8871.0      ...        \n",
       "mean       0.001195      0.016948       1.0       1.0     1.0      ...        \n",
       "std        0.034546      0.129076       0.0       0.0     0.0      ...        \n",
       "min        0.000000      0.000000       1.0       1.0     1.0      ...        \n",
       "25%        0.000000      0.000000       1.0       1.0     1.0      ...        \n",
       "50%        0.000000      0.000000       1.0       1.0     1.0      ...        \n",
       "75%        0.000000      0.000000       1.0       1.0     1.0      ...        \n",
       "max        1.000000      1.000000       1.0       1.0     1.0      ...        \n",
       "\n",
       "        BOATS   WALKER  KIDSTUFF   CARDS  PLATES       AGEFLAG      HOMEOWNR  \\\n",
       "count  2028.0  10501.0    1536.0  1041.0   560.0  65864.000000  73184.000000   \n",
       "mean      1.0      1.0       1.0     1.0     1.0      0.870643      0.715375   \n",
       "std       0.0      0.0       0.0     0.0     0.0      0.335598      0.451239   \n",
       "min       1.0      1.0       1.0     1.0     1.0      0.000000      0.000000   \n",
       "25%       1.0      1.0       1.0     1.0     1.0      1.000000      0.000000   \n",
       "50%       1.0      1.0       1.0     1.0     1.0      1.000000      1.000000   \n",
       "75%       1.0      1.0       1.0     1.0     1.0      1.000000      1.000000   \n",
       "max       1.0      1.0       1.0     1.0     1.0      1.000000      1.000000   \n",
       "\n",
       "           MAILCODE      HPHONE_D      TARGET_B  \n",
       "count  95412.000000  95412.000000  95412.000000  \n",
       "mean       0.014663      0.500618      0.050759  \n",
       "std        0.120199      0.500002      0.219506  \n",
       "min        0.000000      0.000000      0.000000  \n",
       "25%        0.000000      0.000000      0.000000  \n",
       "50%        0.000000      1.000000      0.000000  \n",
       "75%        0.000000      1.000000      0.000000  \n",
       "max        1.000000      1.000000      1.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bools.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several features contain only very few actual feature values. These might get dropped by the sparsity transformer later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning[bool_feature_names] = bools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_transformer = ColumnTransformer([\n",
    "    (\"truncate_zip\",\n",
    "     ZipCodeFormatter(),\n",
    "     ['ZIP']\n",
    "     )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip = zip_transformer.fit_transform(learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a quick sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CONTROLN\n",
       "95515     61081\n",
       "148535    91326\n",
       "15078     27017\n",
       "172556    95953\n",
       "7112      33176\n",
       "Name: ZIP, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning.ZIP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[61081.],\n",
       "       [91326.],\n",
       "       [27017.],\n",
       "       [95953.],\n",
       "       [33176.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the zip coode feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.ZIP = zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories\n",
    "\n",
    "\n",
    "Some categories are already created on import of the data. Additionally, we will have to treat some special cases:\n",
    "\n",
    "* Multibyte features. These are features that group together several related nominal features. These are mainly the promotion history codes. Recency, Frequency and Amount as of a particular mailing are glued together in one feature. For RFA_2 and additionally MDMAUD, the major donor matrix, the features were already spread out by the supplier of the data. These two were dropped on import of the CSV file and their spread out features kept.\n",
    "\n",
    "* OSOURCE: It identifies the origin of the data for a particular record. However, it has so many levels that the feature space would get inflated heavily by one-hot encoding. For this feature, hasing is employed.\n",
    "\n",
    "* TCODE: Special treatment will also be necessary for the TCODE feature. It describes the title code (Ms., Hon., and so on) in an unfortunate integer coding ranging from 1e0 to 1e4. For EDA, this will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TCODE', 'STATE', 'PVASTATE', 'DOMAIN', 'CLUSTER', 'CHILD03', 'CHILD07',\n",
       "       'CHILD12', 'CHILD18', 'GENDER', 'WEALTH1', 'DATASRCE', 'SOLP3', 'SOLIH',\n",
       "       'WEALTH2', 'GEOCODE', 'LIFESRC', 'RFA_2R', 'RFA_2F', 'RFA_2A',\n",
       "       'MDMAUD_R', 'MDMAUD_F', 'MDMAUD_A', 'GEOCODE2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning.select_dtypes(include=\"category\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treating multibyte features and OSOURCE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OSOURCE', 'RFA_3', 'RFA_4', 'RFA_5', 'RFA_6', 'RFA_7', 'RFA_8', 'RFA_9', 'RFA_10', 'RFA_11', 'RFA_12', 'RFA_13', 'RFA_14', 'RFA_15', 'RFA_16', 'RFA_17', 'RFA_18', 'RFA_19', 'RFA_20', 'RFA_21', 'RFA_22', 'RFA_23', 'RFA_24']\n"
     ]
    }
   ],
   "source": [
    "print(dl.nominal_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://booking.ai/dont-be-tricked-by-the-hashing-trick-192a6aae3087\n",
    "\n",
    "https://towardsdatascience.com/smarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_transformer = ColumnTransformer([\n",
    "    (\"hasher\",\n",
    "     HashingEncoder(),\n",
    "     ['OSOURCE']\n",
    "    )\n",
    "])\n",
    "\n",
    "multibyte_transformer = ColumnTransformer([\n",
    "    (\"promotion_history_spreader\",\n",
    "     MultiByteExtract([\"R\", \"F\", \"A\"]),\n",
    "     dl.nominal_features[1:]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the transormations to all RFA_* features and the OSOURCE feature and extract the new feature names to build a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = hash_transformer.fit_transform(learning)\n",
    "feature_names_h = [n[n.find('__')+2:]\n",
    "                 for n in hash_transformer.get_feature_names()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "multibytes = multibyte_transformer.fit_transform(learning)\n",
    "feature_names_m = [n[n.find('__')+2:]\n",
    "                 for n in multibyte_transformer.get_feature_names()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge learning and the new nominal features, then drop the originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "multibytes = pd.DataFrame(data=multibytes, columns=feature_names_m,\n",
    "                   index=learning.index).astype(\"category\")\n",
    "learning = learning.merge(multibytes, on=learning.index.name)\n",
    "\n",
    "hashes = pd.DataFrame(data=hashes, columns=feature_names_h,\n",
    "                   index=learning.index)\n",
    "learning = learning.merge(hashes, on=learning.index.name)\n",
    "\n",
    "learning = learning.drop(dl.nominal_features, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dates\n",
    "\n",
    "There are several date features. ODATEDW is the date the record was added, DOB the birth date. ADATE_* and RDATE_* are from the promotion history. ADATE_* is the date of a mailing, RDATE_* the date the donation for the corresponding mailing was received. While these dates are not of particular interest (very low variance), the time it took to respond might be.\n",
    "\n",
    "Two different transformations are applied:\n",
    "\n",
    "1. ODATEDW, DOB: Get transformed to years before 1997 -> membership duration, age\n",
    "2. For the promotion history, as specified above, the time for response in months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ODATEDW', 'DOB', 'ADATE_2', 'ADATE_3', 'ADATE_4', 'ADATE_5', 'ADATE_6', 'ADATE_7', 'ADATE_8', 'ADATE_9', 'ADATE_10', 'ADATE_11', 'ADATE_12', 'ADATE_13', 'ADATE_14', 'ADATE_15', 'ADATE_16', 'ADATE_17', 'ADATE_18', 'ADATE_19', 'ADATE_20', 'ADATE_21', 'ADATE_22', 'ADATE_23', 'ADATE_24', 'RDATE_3', 'RDATE_4', 'RDATE_5', 'RDATE_6', 'RDATE_7', 'RDATE_8', 'RDATE_9', 'RDATE_10', 'RDATE_11', 'RDATE_12', 'RDATE_13', 'RDATE_14', 'RDATE_15', 'RDATE_16', 'RDATE_17', 'RDATE_18', 'RDATE_19', 'RDATE_20', 'RDATE_21', 'RDATE_22', 'RDATE_23', 'RDATE_24', 'LASTDATE', 'MINRDATE', 'MAXRDATE', 'FISTDATE', 'NEXTDATE', 'MAXADATE']\n"
     ]
    }
   ],
   "source": [
    "print(dl.date_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, parse all date features into datetime values. This also takes care of dates that by the default pivot fall into the 21st century by subtracting 100 years for these.\n",
    "Invalid dates (shorter than 3 digits, 3 digits are fixed as usually the format is yym) are set to NaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_transformer = ColumnTransformer([\n",
    "    (\"parse_dates\",\n",
    "     ParseDates(treat_errors='ignore'),\n",
    "     dl.date_features\n",
    "     )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = date_transformer.fit_transform(learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_feature_names = [n[n.find('__')+2:]\n",
    "                 for n in date_transformer.get_feature_names()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.DataFrame(dates, columns=date_feature_names, index=learning.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning[date_feature_names] = dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we transform the dates from the giving history. First, we create two dataframes with the sending dates of the mailings and the dates when the gift (donation) for these was received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "don_hist_transformer = ColumnTransformer([\n",
    "    (\"months_to_donation\",\n",
    "     MonthsToDonation(),\n",
    "     dl.don_hist_dates\n",
    "     )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "donation_responses = don_hist_transformer.fit_transform(learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "don_hist_feature_names = [n[n.find('__')+2:]\n",
    "                 for n in don_hist_transformer.get_feature_names()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "donation_responses = pd.DataFrame(\n",
    "    donation_responses, index=learning.index, columns=don_hist_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning = learning.merge(donation_responses, on=learning.index.name)\n",
    "learning.drop(dl.don_hist_dates, axis=1, inplace=True)\n",
    "learning.drop(\"ADATE_2\", axis=1, inplace=True) # This is a constant feature, containing the sending date of the current mailing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compute the membership years and age of the records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_transformer = ColumnTransformer([\n",
    "    (\"relative_age\",\n",
    "     ComputeAge(),\n",
    "    ['ODATEDW', 'DOB'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_ages = age_transformer.fit_transform(learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_feature_names = [n[n.find('__')+2:]\n",
    "                 for n in age_transformer.get_feature_names()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_ages = pd.DataFrame(rel_ages, index=learning.index,columns=age_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning[age_feature_names] = rel_ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "duration_transformer = ColumnTransformer([\n",
    "    (\"durations\",\n",
    "     ComputeDuration(),\n",
    "     dl.don_summary_dates)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = duration_transformer.fit_transform(learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-0fe6efbfab00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m duration_feature_names = [n[n.find('__')+2:]\n\u001b[1;32m----> 2\u001b[1;33m                  for n in duration_transformer.get_feature_names()]\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mget_feature_names\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    339\u001b[0m                                      % (str(name), type(trans).__name__))\n\u001b[0;32m    340\u001b[0m             feature_names.extend([name + \"__\" + f for f in\n\u001b[1;32m--> 341\u001b[1;33m                                   trans.get_feature_names()])\n\u001b[0m\u001b[0;32m    342\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\unine\\Master_Thesis\\code_data\\code\\kdd98\\transformers.py\u001b[0m in \u001b[0;36mget_feature_names\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2015\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[0;32m   2016\u001b[0m                          \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2017\u001b[1;33m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[0;32m   2018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2019\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "duration_feature_names = [n[n.find('__')+2:]\n",
    "                 for n in duration_transformer.get_feature_names()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = pd.DataFrame(durations, index=learning.index,columns=duration_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning[durations_feature_names] = durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A look at the label (amount donated in US dollars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning.loc[learning.TARGET_D > 0, 'TARGET_D'].hist(bins=50)\n",
    "sns.distplot(learning.loc[learning.TARGET_D > 0, 'TARGET_D'], bins=100, hist_kws={'alpha': 0.4});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning.TARGET_D.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Most donations are below 20 dollars.\n",
    "* Spikes are visible for 5, 10, 15, 20, 25, 50, 100 and 200 $\n",
    "* The distribution is right-skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the claim from the documentation that donations are positively correlated with the time since the last donation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.LASTDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='LASTDATE',y='TARGET_D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations\n",
    "\n",
    "-> Product moment covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are so many features, we will plot those who have a significant correlation only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_all = learning.drop(['TARGET_B','TARGET_D'], axis=1).corr()\n",
    "\n",
    "sns.heatmap(corr_all[corr_all >= 0.4 | corr_all <= -0.4],\n",
    "            cmap=\"viridis\", vmax=1.0, center = 0.0, square=True,\n",
    "            linewidths = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations between numerical features, excluding US census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exclude_census_numeric = learning[learning.columns.difference(dl.us_census_features)].select_dtypes(include=[\"float64\", \"int64\"])\n",
    "data_exclude_census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exclude_census_corr = data_exclude_census[data_exclude_census.columns.difference(['TARGET_B','TARGET_D'])].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(data_exclude_census_corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "#cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "sns.heatmap(data_exclude_census_corr, mask=mask, cmap=\"viridis\", vmax=1.0, center=0,\n",
    "            square=True, linewidths=.1, cbar_kws={\"shrink\": .5}, xticklabels=True,yticklabels=True)\n",
    "save_fig(fig_id=\"numeric_correlations_without_census\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_exclude_census_corr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giving history correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prom_hist_f = list(donation_responses.columns)+list(multibytes.columns)+dl.promotion_history_summary+dl.giving_history_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promotion_history_features = learning.loc[:,prom_hist_f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prom_giving_corr = promotion_history_features[promotion_history_features.columns.difference(['TARGET_B','TARGET_D'])].corr()\n",
    "mask = np.zeros_like(prom_giving_corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "#cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "sns.heatmap(prom_giving_corr, mask=mask, cmap=\"viridis\", vmax=1.0, center=0,\n",
    "            square=True, linewidths=.3, cbar_kws={\"shrink\": .5}, xticklabels=True,yticklabels=True)\n",
    "save_fig(fig_id=\"correlations_promotion_giving_history\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puttting donors on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(learning.TARGET_D.apply(lambda v: 1.0 if v != 0.0 else 0.0).sum())\n",
    "print(learning.TARGET_B.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_donors_by_zip = learning[['ZIP', 'TARGET_B']].groupby('ZIP', as_index=False).agg('sum') # number of people who donated\n",
    "num_members_by_zip = learning[['ZIP', 'TARGET_B']].groupby('ZIP', as_index=False).agg('count') # number of people who are registered at that ZIP\n",
    "cum_donation_by_zip = learning[['ZIP', 'TARGET_D']].groupby('ZIP', as_index=False).agg('sum')\n",
    "zip_states = learning[['ZIP','STATE']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_zip = cum_donation_by_zip.merge(num_members_by_zip, on='ZIP').merge(zip_states, on='ZIP')\n",
    "data_by_zip.columns = [\"ZIP\", \"CumDonation\", \"MemberCount\", \"State\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_donation(row):\n",
    "    if row.CumDonation != 0.0:\n",
    "        return row.CumDonation/(1.0 if row.MemberCount == 0.0 else row.MemberCount)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "data_by_zip['RelDonation'] = data_by_zip.apply(rel_donation,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Here\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "\n",
    "def do_geo_query(q):\n",
    "    geolocator = Here(app_id=\"ZJBxigwxa1QPHlWrtWH6\", app_code=\"OJBun02aepkFbuHmYn1bOg\")\n",
    "    geocode = RateLimiter(geolocator.geocode, min_delay_seconds=0.01, max_retries=4)\n",
    "    try:\n",
    "        return geolocator.geocode(query=q, exactly_one=True)\n",
    "    except GeocoderTimedOut:\n",
    "        return do_geo_query(q)\n",
    "\n",
    "def get_loc(example):\n",
    "    if example.ZIP:\n",
    "        zip = str(int(example.ZIP)).rjust(5, '0')\n",
    "        q = {'postalcode': zip, 'state': example.State}\n",
    "        return do_geo_query(q)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def extract_coords(location):\n",
    "    return [location.latitude, location.longitude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "try:\n",
    "    zip_data = open(\"zip_data.pkl\", \"rb\")\n",
    "    locations = pickle.load(zip_data)\n",
    "    zip_data.close()\n",
    "except Exception as e:\n",
    "    locations = data_by_zip.progress_apply(get_loc, axis=1)\n",
    "    locations = pd.DataFrame(locations, columns=\"location\")\n",
    "    locations['ZIP'] = data_by_zip.ZIP\n",
    "    zip_data = open(\"zip_data.pkl\", \"wb\")\n",
    "    pickle.dump(locations, zip_data)\n",
    "    zip_data.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_zip = data_by_zip.merge(locations, on='ZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_zip.loc[:,'longitude'] = data_by_zip.location.apply(lambda l: l.longitude if l != None else None)\n",
    "data_by_zip.loc[:,'latitude'] = data_by_zip.location.apply(lambda l: l.latitude if l != None else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AA stands for armed services. ZIP codes don't work here, they point anywhere. Also, we only include locations where someone has actually donated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_zip1 = data_by_zip.loc[data_by_zip.State not in ['AA','AE','AP'],:]\n",
    "data_by_zip2 = data_by_zip1.loc[data_by_zip1.CumDonation > 0.0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "import cartopy.feature as cfeature\n",
    "fig = plt.figure(figsize=(20,16))\n",
    "\n",
    "osm_terrain = cimgt.OSM()\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1, projection=osm_terrain.crs)\n",
    "\n",
    "ax.set_extent([-166, -65, 10, 65], crs=ccrs.PlateCarree())\n",
    "ax.add_image(osm_terrain, 6)\n",
    "\n",
    "lon = data_by_zip2.longitude\n",
    "lat = data_by_zip2.latitude\n",
    "mc = data_by_zip2.MemberCount\n",
    "cd = data_by_zip2.CumDonation\n",
    "rd = data_by_zip2.RelDonation\n",
    "\n",
    "#ax.scatter(lon, lat, s=cd, c=rd, alpha=0.3, cmap=\"viridis\", transform=ccrs.PlateCarree())\n",
    "data_by_zip2.plot(kind=\"scatter\",x=\"longitude\",y=\"latitude\",ax=ax,\n",
    "                  s=cd, c=rd, label=\"Cumulative Donations\",\n",
    "                  legend=True, alpha=0.5, cmap=\"viridis_r\",\n",
    "                  subplots=True, colorbar=True, transform=ccrs.PlateCarree())\n",
    "ax.autoscale_view()\n",
    "            \n",
    "save_fig(fig_id=\"donations_geographical\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Most donations come from the urban areas, especially San Francisco, Los Angeles, Miami, Chicago and Detroit. To a lesser extent, cities like Houston, Dallas, Minneapolis, Atlanta, Tampa, Seattle and Phoenix can be made out.\n",
    "* Interestingly, the East Coast has not donated, despite featuring some large metropolitan areas like New York, Boston, or Washington"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The US census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = learning[dl.us_census_features]\n",
    "census_corr = census.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(census_corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "sns.heatmap(census_corr, mask=mask, cmap=cmap, vmax=1.0, center=0,\n",
    "            square=True, linewidths=.2, cbar_kws={\"shrink\": .5})\n",
    "save_fig(fig_id=\"correlation_census\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census.select_dtypes(include=\"int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Income, Wealth and donations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_targ = sns.violinplot(x=\"INCOME\", y=\"TARGET_D\", data=learning.loc[learning.TARGET_D > 0.0, [\"INCOME\",\"TARGET_D\"]])\n",
    "inc_targ.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weal1_targ = sns.violinplot(x=\"WEALTH1\", y=\"TARGET_D\", data=learning.loc[learning.TARGET_D > 0.0, [\"WEALTH1\",\"TARGET_D\"]])\n",
    "weal1_targ.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weal2_targ = sns.violinplot(x=\"WEALTH2\", y=\"TARGET_D\", data=learning.loc[learning.TARGET_D > 0.0, [\"WEALTH2\",\"TARGET_D\"]])\n",
    "weal2_targ.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"WEALTH2\", y=\"TARGET_D\", hue=\"MAJOR\",\n",
    "            kind=\"violin\", inner=\"stick\", split=True, data=learning.loc[learning.TARGET_D > 0.0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"CLUSTER\", y=\"TARGET_D\", kind=\"box\", data=learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(learning.loc[learning.TARGET_D > 0.0,\n",
    "                          'TARGET_D'], bins=50, kde=False, rug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.select_dtypes(include=np.float).hist(bins=50, figsize=(50, 50))\n",
    "plt.show()\n",
    "save_fig(\"float_feature_histograms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some promising fetures and their impact on the label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "A first look at important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from kdd98.transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = learning.drop([\"TARGET_B\", \"TARGET_D\",\"ADATE_2\", \"TCODE\"], axis=1)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.select_dtypes(include=\"category\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"one_hot\",  OneHotEncoder(impute_missing=True,use_cat_names=True,return_df=True))\n",
    "])\n",
    "\n",
    "categories_transformer = ColumnTransformer([\n",
    "    (\"cat_encoder\",\n",
    "     cat_pipe,\n",
    "     list(X.select_dtypes(include=\"category\").columns))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = categories_transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(categories_transformer.named_transformers_.cat_encoder.named_steps.one_hot.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = pd.DataFrame(cats, columns = list(categories_transformer.named_transformers_.cat_encoder.named_steps.one_hot.get_feature_names()), index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.merge(cats, on=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(X.select_dtypes(include=\"category\").columns,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centered = X - X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centered = X_centered.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centered[X.select_dtypes(include=\"object\").columns] = X_centered[X.select_dtypes(include=\"object\").columns].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_centered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA()\n",
    "pca.fit(X_centered,)\n",
    "result = pd.DataFrame(pca.transform(X_centered), columns=[\n",
    "                      \"PCA%i\" % i for i in range(n_comp)], index=X.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
