# Conclusions

## Comparison With Cup Winners

The KDD-CUP committee evaluated the results based on the net revenue generated on the validation sample. 
The measure used was the sum (the actual donation amount - \$0.68) over all records for which the expected revenue (or predicted value of the donation) is over \$0.68. 
This measure is simple, objective and a direct measure of profit. Table 2 depicts the results. The participants are listed based on the last column.

```{r benchmark-cup-winners, results="asis"}
cup_winners <- t(data.frame(GainSmarts = c(56330, -0.68, 0.26, 5.57, 499.32, 14712),
                            SAS = c(55838, -0.68, 0.26, 5.64, 499.32, 14662),
                            Quadstone = c(57836, -0.68, 0.24, 5.66, 499.32, 13954),
                            CARRL = c(55650, -0.68, 0.25, 5.61, 499.32, 13825),
                            Amdocs = c(51906, -0.68, 0.27, 5.69, 499.32, 13794)))
colnames(cup_winners) <- c('N*','Min','Mean','Std', 'Max','Sum')

knitr::kable(cup_winners,
             booktabs = T,
             caption = "Top five of the KDD-CUP participants. N* denotes the number for which the predicted donation amount is > $0.68. Sum is the total profit, meaning the donation minus $0.68 for each example.") %>%
    kableExtra::kable_styling(latex_options=c("hold_position", position="Center")) %>%
    kableExtra::add_header_above(c(" "=1," "=1,"Amount, $"=5))
```


## Biggest Problems Remaining

* Feature Extraction

* Feature Selection

* Choice of Models

* Poor prediction performance: Non-gaussian distribution of $\hat{y}_b$, which violates assumptions for Heckman-correction., bias-variance tradeoff

Prediction Error $PE(z) = \sigma_{\epsilon}^2+\text{Bias}^2(\hat{f}(z))+\text{Var}(\hat{f}(z))$. When model more complex, local structure picked up, coefficient estimates suffer from high Var as more terms included in model -> more bias can lead to decrease in variance, decreasing PE.


* Will be easy to work on these specific areas given the infrastructure created in this thesis