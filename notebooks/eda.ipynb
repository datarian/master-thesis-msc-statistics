{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "This notebook contains all code for the prelimiatory analysis of the KDD Cup 98 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "if not os.getcwd()[-4:] == 'code':\n",
    "    os.chdir(\"../code\")\n",
    "import kdd98.data_loader as dl\n",
    "import kdd98.utils_transformer as ut\n",
    "from kdd98.transformers import *\n",
    "from kdd98.config import App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# seaborn config\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "sns.set_style('ticks')\n",
    "sns.axes_style({'spines.right': False,\n",
    "                'axes.spines.top': False})\n",
    "sns.set_palette(App.config(\"color_palette\"))\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# figures:\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \"../../\"\n",
    "CHAPTER_ID = \"eda\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"figures\", CHAPTER_ID)\n",
    "\n",
    "if not os.path.exists(IMAGES_PATH):\n",
    "    os.makedirs(IMAGES_PATH)\n",
    "\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the learning dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set working directory to main code folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = dl.KDD98DataLoader(\"cup98LRN.txt\")\n",
    "learning = data_loader.get_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first, general look at the data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 95412 entries, 95515 to 185114\n",
      "Columns: 478 entries, ODATEDW to GEOCODE2\n",
      "dtypes: category(24), datetime64[ns](53), float64(50), int64(297), object(54)\n",
      "memory usage: 333.4+ MB\n"
     ]
    }
   ],
   "source": [
    "learning.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are 478 features\n",
    "* A total of 95412 examples\n",
    "* 24 categorical features, 53 datetime features, 50 continuous features, 297 discrete features and 54 string features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODATEDW</th>\n",
       "      <th>OSOURCE</th>\n",
       "      <th>TCODE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>MAILCODE</th>\n",
       "      <th>PVASTATE</th>\n",
       "      <th>DOB</th>\n",
       "      <th>NOEXCH</th>\n",
       "      <th>RECINHSE</th>\n",
       "      <th>...</th>\n",
       "      <th>TARGET_D</th>\n",
       "      <th>HPHONE_D</th>\n",
       "      <th>RFA_2R</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>RFA_2A</th>\n",
       "      <th>MDMAUD_R</th>\n",
       "      <th>MDMAUD_F</th>\n",
       "      <th>MDMAUD_A</th>\n",
       "      <th>CLUSTER2</th>\n",
       "      <th>GEOCODE2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONTROLN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95515</th>\n",
       "      <td>1989-01-01</td>\n",
       "      <td>GRI</td>\n",
       "      <td>0</td>\n",
       "      <td>IL</td>\n",
       "      <td>61081.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1937-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>39.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148535</th>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>BOA</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>91326.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1952-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>2</td>\n",
       "      <td>G</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15078</th>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>AMH</td>\n",
       "      <td>1</td>\n",
       "      <td>NC</td>\n",
       "      <td>27017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>60.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172556</th>\n",
       "      <td>1987-01-01</td>\n",
       "      <td>BRY</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>95953.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1928-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>41.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7112</th>\n",
       "      <td>1986-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FL</td>\n",
       "      <td>33176.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1920-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>26.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 478 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ODATEDW OSOURCE TCODE STATE      ZIP MAILCODE PVASTATE        DOB  \\\n",
       "CONTROLN                                                                        \n",
       "95515    1989-01-01     GRI     0    IL  61081.0      NaN      NaN 1937-12-01   \n",
       "148535   1994-01-01     BOA     1    CA  91326.0      NaN      NaN 1952-02-01   \n",
       "15078    1990-01-01     AMH     1    NC  27017.0      NaN      NaN        NaT   \n",
       "172556   1987-01-01     BRY     0    CA  95953.0      NaN      NaN 1928-01-01   \n",
       "7112     1986-01-01     NaN     0    FL  33176.0      NaN      NaN 1920-01-01   \n",
       "\n",
       "         NOEXCH RECINHSE   ...    TARGET_D HPHONE_D RFA_2R RFA_2F RFA_2A  \\\n",
       "CONTROLN                   ...                                             \n",
       "95515         0      NaN   ...           0        0      L      4      E   \n",
       "148535        0      NaN   ...           0        0      L      2      G   \n",
       "15078         0      NaN   ...           0        1      L      4      E   \n",
       "172556        0      NaN   ...           0        1      L      4      E   \n",
       "7112          0        X   ...           0        1      L      2      F   \n",
       "\n",
       "          MDMAUD_R MDMAUD_F MDMAUD_A CLUSTER2 GEOCODE2  \n",
       "CONTROLN                                                \n",
       "95515            X        X        X     39.0        C  \n",
       "148535           X        X        X      1.0        A  \n",
       "15078            X        X        X     60.0        C  \n",
       "172556           X        X        X     41.0        C  \n",
       "7112             X        X        X     26.0        A  \n",
       "\n",
       "[5 rows x 478 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ZIP', 'AGE', 'NUMCHLD', 'INCOME', 'HIT', 'MBCRAFT', 'MBGARDEN',\n",
      "       'MBBOOKS', 'MBCOLECT', 'MAGFAML',\n",
      "       ...\n",
      "       'RAMNT_24', 'RAMNTALL', 'NGIFTALL', 'CARDGIFT', 'MINRAMNT', 'MAXRAMNT',\n",
      "       'LASTGIFT', 'TIMELAG', 'AVGGIFT', 'CLUSTER2'],\n",
      "      dtype='object', length=347)\n"
     ]
    }
   ],
   "source": [
    "numerical = learning.select_dtypes(include=np.number).columns\n",
    "print(numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features\n",
    "\n",
    "Categories were defined on import of the csv data. The categories were identified in the dataset dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['STATE', 'PVASTATE', 'DOMAIN', 'CLUSTER', 'CHILD03', 'CHILD07',\n",
      "       'CHILD12', 'CHILD18', 'GENDER', 'WEALTH1', 'DATASRCE', 'SOLP3', 'SOLIH',\n",
      "       'WEALTH2', 'GEOCODE', 'LIFESRC', 'TARGET_D', 'RFA_2R', 'RFA_2F',\n",
      "       'RFA_2A', 'MDMAUD_R', 'MDMAUD_F', 'MDMAUD_A', 'GEOCODE2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "categories = learning.select_dtypes(include='category').columns\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>PVASTATE</th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>CHILD03</th>\n",
       "      <th>CHILD07</th>\n",
       "      <th>CHILD12</th>\n",
       "      <th>CHILD18</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>WEALTH1</th>\n",
       "      <th>...</th>\n",
       "      <th>GEOCODE</th>\n",
       "      <th>LIFESRC</th>\n",
       "      <th>TARGET_D</th>\n",
       "      <th>RFA_2R</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>RFA_2A</th>\n",
       "      <th>MDMAUD_R</th>\n",
       "      <th>MDMAUD_F</th>\n",
       "      <th>MDMAUD_A</th>\n",
       "      <th>GEOCODE2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>95412</td>\n",
       "      <td>1458</td>\n",
       "      <td>93096</td>\n",
       "      <td>93096</td>\n",
       "      <td>1146</td>\n",
       "      <td>1566</td>\n",
       "      <td>1811</td>\n",
       "      <td>2847</td>\n",
       "      <td>92455</td>\n",
       "      <td>50680</td>\n",
       "      <td>...</td>\n",
       "      <td>15244</td>\n",
       "      <td>41380</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>CA</td>\n",
       "      <td>P</td>\n",
       "      <td>R2</td>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>F</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>17343</td>\n",
       "      <td>1453</td>\n",
       "      <td>13623</td>\n",
       "      <td>3979</td>\n",
       "      <td>869</td>\n",
       "      <td>1061</td>\n",
       "      <td>1149</td>\n",
       "      <td>1442</td>\n",
       "      <td>51277</td>\n",
       "      <td>7585</td>\n",
       "      <td>...</td>\n",
       "      <td>3914</td>\n",
       "      <td>20027</td>\n",
       "      <td>90569</td>\n",
       "      <td>95412</td>\n",
       "      <td>47675</td>\n",
       "      <td>46964</td>\n",
       "      <td>95118</td>\n",
       "      <td>95118</td>\n",
       "      <td>95118</td>\n",
       "      <td>34484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        STATE PVASTATE DOMAIN CLUSTER CHILD03 CHILD07 CHILD12 CHILD18 GENDER  \\\n",
       "count   95412     1458  93096   93096    1146    1566    1811    2847  92455   \n",
       "unique     57        2     16      53       3       3       3       3      6   \n",
       "top        CA        P     R2      40       M       M       M       M      F   \n",
       "freq    17343     1453  13623    3979     869    1061    1149    1442  51277   \n",
       "\n",
       "       WEALTH1   ...    GEOCODE LIFESRC TARGET_D RFA_2R RFA_2F RFA_2A  \\\n",
       "count    50680   ...      15244   41380    95412  95412  95412  95412   \n",
       "unique      10   ...          7       3       71      1      4      4   \n",
       "top          9   ...         12       2        0      L      1      F   \n",
       "freq      7585   ...       3914   20027    90569  95412  47675  46964   \n",
       "\n",
       "       MDMAUD_R MDMAUD_F MDMAUD_A GEOCODE2  \n",
       "count     95412    95412    95412    95093  \n",
       "unique        5        4        5        4  \n",
       "top           X        X        X        A  \n",
       "freq      95118    95118    95118    34484  \n",
       "\n",
       "[4 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning.loc[:, categories].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Features\n",
    "\n",
    "These features have mixed datatypes and are encoded as strings. This hints at noisy data and features that will have to be transformed before becoming usable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['OSOURCE', 'TCODE', 'MAILCODE', 'NOEXCH', 'RECINHSE', 'RECP3',\n",
      "       'RECPGVG', 'RECSWEEP', 'AGEFLAG', 'HOMEOWNR', 'MAJOR', 'COLLECT1',\n",
      "       'VETERANS', 'BIBLE', 'CATLG', 'HOMEE', 'PETS', 'CDPLAY', 'STEREO',\n",
      "       'PCOWNERS', 'PHOTO', 'CRAFTS', 'FISHER', 'GARDENIN', 'BOATS', 'WALKER',\n",
      "       'KIDSTUFF', 'CARDS', 'PLATES', 'PEPSTRFL', 'RFA_3', 'RFA_4', 'RFA_5',\n",
      "       'RFA_6', 'RFA_7', 'RFA_8', 'RFA_9', 'RFA_10', 'RFA_11', 'RFA_12',\n",
      "       'RFA_13', 'RFA_14', 'RFA_15', 'RFA_16', 'RFA_17', 'RFA_18', 'RFA_19',\n",
      "       'RFA_20', 'RFA_21', 'RFA_22', 'RFA_23', 'RFA_24', 'TARGET_B',\n",
      "       'HPHONE_D'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "objects = learning.select_dtypes(include='object').columns\n",
    "print(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OSOURCE</th>\n",
       "      <th>TCODE</th>\n",
       "      <th>MAILCODE</th>\n",
       "      <th>NOEXCH</th>\n",
       "      <th>RECINHSE</th>\n",
       "      <th>RECP3</th>\n",
       "      <th>RECPGVG</th>\n",
       "      <th>RECSWEEP</th>\n",
       "      <th>AGEFLAG</th>\n",
       "      <th>HOMEOWNR</th>\n",
       "      <th>...</th>\n",
       "      <th>RFA_17</th>\n",
       "      <th>RFA_18</th>\n",
       "      <th>RFA_19</th>\n",
       "      <th>RFA_20</th>\n",
       "      <th>RFA_21</th>\n",
       "      <th>RFA_22</th>\n",
       "      <th>RFA_23</th>\n",
       "      <th>RFA_24</th>\n",
       "      <th>TARGET_B</th>\n",
       "      <th>HPHONE_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>94484</td>\n",
       "      <td>95412</td>\n",
       "      <td>1399</td>\n",
       "      <td>95405</td>\n",
       "      <td>6703</td>\n",
       "      <td>2017</td>\n",
       "      <td>114</td>\n",
       "      <td>1617</td>\n",
       "      <td>65864</td>\n",
       "      <td>73184</td>\n",
       "      <td>...</td>\n",
       "      <td>67762</td>\n",
       "      <td>74149</td>\n",
       "      <td>70920</td>\n",
       "      <td>45212</td>\n",
       "      <td>60200</td>\n",
       "      <td>69764</td>\n",
       "      <td>39138</td>\n",
       "      <td>58439</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>895</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>121</td>\n",
       "      <td>107</td>\n",
       "      <td>79</td>\n",
       "      <td>101</td>\n",
       "      <td>116</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>MBC</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>E</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>A1E</td>\n",
       "      <td>A1E</td>\n",
       "      <td>A1E</td>\n",
       "      <td>A1E</td>\n",
       "      <td>A1E</td>\n",
       "      <td>A1E</td>\n",
       "      <td>A1F</td>\n",
       "      <td>A1E</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4539</td>\n",
       "      <td>40917</td>\n",
       "      <td>1399</td>\n",
       "      <td>95085</td>\n",
       "      <td>6703</td>\n",
       "      <td>2017</td>\n",
       "      <td>114</td>\n",
       "      <td>1617</td>\n",
       "      <td>57344</td>\n",
       "      <td>52354</td>\n",
       "      <td>...</td>\n",
       "      <td>6773</td>\n",
       "      <td>7186</td>\n",
       "      <td>7248</td>\n",
       "      <td>6408</td>\n",
       "      <td>6729</td>\n",
       "      <td>7233</td>\n",
       "      <td>4607</td>\n",
       "      <td>7227</td>\n",
       "      <td>90569</td>\n",
       "      <td>47765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       OSOURCE  TCODE MAILCODE NOEXCH RECINHSE RECP3 RECPGVG RECSWEEP AGEFLAG  \\\n",
       "count    94484  95412     1399  95405     6703  2017     114     1617   65864   \n",
       "unique     895     55        1      2        1     1       1        1       2   \n",
       "top        MBC      0        B      0        X     X       X        X       E   \n",
       "freq      4539  40917     1399  95085     6703  2017     114     1617   57344   \n",
       "\n",
       "       HOMEOWNR   ...    RFA_17 RFA_18 RFA_19 RFA_20 RFA_21 RFA_22 RFA_23  \\\n",
       "count     73184   ...     67762  74149  70920  45212  60200  69764  39138   \n",
       "unique        2   ...       117    121    107     79    101    116     86   \n",
       "top           H   ...       A1E    A1E    A1E    A1E    A1E    A1E    A1F   \n",
       "freq      52354   ...      6773   7186   7248   6408   6729   7233   4607   \n",
       "\n",
       "       RFA_24 TARGET_B HPHONE_D  \n",
       "count   58439    95412    95412  \n",
       "unique     96        2        2  \n",
       "top       A1E        0        1  \n",
       "freq     7227    90569    47765  \n",
       "\n",
       "[4 rows x 54 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning.loc[:, objects].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date features\n",
    "These are imported as strings and will have to be transformed later on to become useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODATEDW</th>\n",
       "      <th>DOB</th>\n",
       "      <th>ADATE_2</th>\n",
       "      <th>ADATE_3</th>\n",
       "      <th>ADATE_4</th>\n",
       "      <th>ADATE_5</th>\n",
       "      <th>ADATE_6</th>\n",
       "      <th>ADATE_7</th>\n",
       "      <th>ADATE_8</th>\n",
       "      <th>ADATE_9</th>\n",
       "      <th>...</th>\n",
       "      <th>RDATE_21</th>\n",
       "      <th>RDATE_22</th>\n",
       "      <th>RDATE_23</th>\n",
       "      <th>RDATE_24</th>\n",
       "      <th>LASTDATE</th>\n",
       "      <th>MINRDATE</th>\n",
       "      <th>MAXRDATE</th>\n",
       "      <th>FISTDATE</th>\n",
       "      <th>NEXTDATE</th>\n",
       "      <th>MAXADATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>95412</td>\n",
       "      <td>71692</td>\n",
       "      <td>95412</td>\n",
       "      <td>93462</td>\n",
       "      <td>93221</td>\n",
       "      <td>61822</td>\n",
       "      <td>91855</td>\n",
       "      <td>86538</td>\n",
       "      <td>91901</td>\n",
       "      <td>84167</td>\n",
       "      <td>...</td>\n",
       "      <td>9513</td>\n",
       "      <td>20873</td>\n",
       "      <td>7859</td>\n",
       "      <td>17738</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95412</td>\n",
       "      <td>95410</td>\n",
       "      <td>85439</td>\n",
       "      <td>95412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>54</td>\n",
       "      <td>935</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>176</td>\n",
       "      <td>188</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1995-01-01 00:00:00</td>\n",
       "      <td>1948-01-01 00:00:00</td>\n",
       "      <td>1997-06-01 00:00:00</td>\n",
       "      <td>1996-06-01 00:00:00</td>\n",
       "      <td>1996-04-01 00:00:00</td>\n",
       "      <td>1996-04-01 00:00:00</td>\n",
       "      <td>1996-03-01 00:00:00</td>\n",
       "      <td>1996-02-01 00:00:00</td>\n",
       "      <td>1996-01-01 00:00:00</td>\n",
       "      <td>1995-11-01 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1994-11-01 00:00:00</td>\n",
       "      <td>1994-09-01 00:00:00</td>\n",
       "      <td>1994-08-01 00:00:00</td>\n",
       "      <td>1994-07-01 00:00:00</td>\n",
       "      <td>1995-12-01 00:00:00</td>\n",
       "      <td>1996-02-01 00:00:00</td>\n",
       "      <td>1995-12-01 00:00:00</td>\n",
       "      <td>1995-01-01 00:00:00</td>\n",
       "      <td>1995-04-01 00:00:00</td>\n",
       "      <td>1997-02-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>15358</td>\n",
       "      <td>1479</td>\n",
       "      <td>95399</td>\n",
       "      <td>93444</td>\n",
       "      <td>92405</td>\n",
       "      <td>61822</td>\n",
       "      <td>91804</td>\n",
       "      <td>81512</td>\n",
       "      <td>85468</td>\n",
       "      <td>80718</td>\n",
       "      <td>...</td>\n",
       "      <td>5006</td>\n",
       "      <td>11195</td>\n",
       "      <td>4522</td>\n",
       "      <td>7861</td>\n",
       "      <td>19896</td>\n",
       "      <td>3041</td>\n",
       "      <td>10563</td>\n",
       "      <td>2957</td>\n",
       "      <td>2253</td>\n",
       "      <td>95014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>1983-06-01 00:00:00</td>\n",
       "      <td>1901-01-01 00:00:00</td>\n",
       "      <td>1997-04-01 00:00:00</td>\n",
       "      <td>1996-04-01 00:00:00</td>\n",
       "      <td>1995-11-01 00:00:00</td>\n",
       "      <td>1996-04-01 00:00:00</td>\n",
       "      <td>1996-01-01 00:00:00</td>\n",
       "      <td>1995-12-01 00:00:00</td>\n",
       "      <td>1995-11-01 00:00:00</td>\n",
       "      <td>1995-09-01 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1994-09-01 00:00:00</td>\n",
       "      <td>1994-09-01 00:00:00</td>\n",
       "      <td>1993-09-01 00:00:00</td>\n",
       "      <td>1993-09-01 00:00:00</td>\n",
       "      <td>1995-03-01 00:00:00</td>\n",
       "      <td>1975-06-01 00:00:00</td>\n",
       "      <td>1975-10-01 00:00:00</td>\n",
       "      <td>1949-12-01 00:00:00</td>\n",
       "      <td>1972-11-01 00:00:00</td>\n",
       "      <td>1996-08-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>1997-01-01 00:00:00</td>\n",
       "      <td>1997-10-01 00:00:00</td>\n",
       "      <td>1997-06-01 00:00:00</td>\n",
       "      <td>1996-06-01 00:00:00</td>\n",
       "      <td>1996-09-01 00:00:00</td>\n",
       "      <td>1996-04-01 00:00:00</td>\n",
       "      <td>1996-03-01 00:00:00</td>\n",
       "      <td>1996-02-01 00:00:00</td>\n",
       "      <td>1996-05-01 00:00:00</td>\n",
       "      <td>1995-11-01 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-08-01 00:00:00</td>\n",
       "      <td>1995-10-01 00:00:00</td>\n",
       "      <td>1995-07-01 00:00:00</td>\n",
       "      <td>1995-04-01 00:00:00</td>\n",
       "      <td>1997-02-01 00:00:00</td>\n",
       "      <td>1997-02-01 00:00:00</td>\n",
       "      <td>1997-02-01 00:00:00</td>\n",
       "      <td>1996-03-01 00:00:00</td>\n",
       "      <td>1997-02-01 00:00:00</td>\n",
       "      <td>1997-02-01 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ODATEDW                  DOB              ADATE_2  \\\n",
       "count                 95412                71692                95412   \n",
       "unique                   54                  935                    2   \n",
       "top     1995-01-01 00:00:00  1948-01-01 00:00:00  1997-06-01 00:00:00   \n",
       "freq                  15358                 1479                95399   \n",
       "first   1983-06-01 00:00:00  1901-01-01 00:00:00  1997-04-01 00:00:00   \n",
       "last    1997-01-01 00:00:00  1997-10-01 00:00:00  1997-06-01 00:00:00   \n",
       "\n",
       "                    ADATE_3              ADATE_4              ADATE_5  \\\n",
       "count                 93462                93221                61822   \n",
       "unique                    2                    8                    1   \n",
       "top     1996-06-01 00:00:00  1996-04-01 00:00:00  1996-04-01 00:00:00   \n",
       "freq                  93444                92405                61822   \n",
       "first   1996-04-01 00:00:00  1995-11-01 00:00:00  1996-04-01 00:00:00   \n",
       "last    1996-06-01 00:00:00  1996-09-01 00:00:00  1996-04-01 00:00:00   \n",
       "\n",
       "                    ADATE_6              ADATE_7              ADATE_8  \\\n",
       "count                 91855                86538                91901   \n",
       "unique                    2                    3                    5   \n",
       "top     1996-03-01 00:00:00  1996-02-01 00:00:00  1996-01-01 00:00:00   \n",
       "freq                  91804                81512                85468   \n",
       "first   1996-01-01 00:00:00  1995-12-01 00:00:00  1995-11-01 00:00:00   \n",
       "last    1996-03-01 00:00:00  1996-02-01 00:00:00  1996-05-01 00:00:00   \n",
       "\n",
       "                    ADATE_9         ...                      RDATE_21  \\\n",
       "count                 84167         ...                          9513   \n",
       "unique                    3         ...                            12   \n",
       "top     1995-11-01 00:00:00         ...           1994-11-01 00:00:00   \n",
       "freq                  80718         ...                          5006   \n",
       "first   1995-09-01 00:00:00         ...           1994-09-01 00:00:00   \n",
       "last    1995-11-01 00:00:00         ...           1995-08-01 00:00:00   \n",
       "\n",
       "                   RDATE_22             RDATE_23             RDATE_24  \\\n",
       "count                 20873                 7859                17738   \n",
       "unique                   13                   17                   14   \n",
       "top     1994-09-01 00:00:00  1994-08-01 00:00:00  1994-07-01 00:00:00   \n",
       "freq                  11195                 4522                 7861   \n",
       "first   1994-09-01 00:00:00  1993-09-01 00:00:00  1993-09-01 00:00:00   \n",
       "last    1995-10-01 00:00:00  1995-07-01 00:00:00  1995-04-01 00:00:00   \n",
       "\n",
       "                   LASTDATE             MINRDATE             MAXRDATE  \\\n",
       "count                 95412                95412                95412   \n",
       "unique                   24                  146                  150   \n",
       "top     1995-12-01 00:00:00  1996-02-01 00:00:00  1995-12-01 00:00:00   \n",
       "freq                  19896                 3041                10563   \n",
       "first   1995-03-01 00:00:00  1975-06-01 00:00:00  1975-10-01 00:00:00   \n",
       "last    1997-02-01 00:00:00  1997-02-01 00:00:00  1997-02-01 00:00:00   \n",
       "\n",
       "                   FISTDATE             NEXTDATE             MAXADATE  \n",
       "count                 95410                85439                95412  \n",
       "unique                  176                  188                    5  \n",
       "top     1995-01-01 00:00:00  1995-04-01 00:00:00  1997-02-01 00:00:00  \n",
       "freq                   2957                 2253                95014  \n",
       "first   1949-12-01 00:00:00  1972-11-01 00:00:00  1996-08-01 00:00:00  \n",
       "last    1996-03-01 00:00:00  1997-02-01 00:00:00  1997-02-01 00:00:00  \n",
       "\n",
       "[6 rows x 53 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = learning.loc[:, dl.date_features]\n",
    "dates.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "\n",
    "We will leverage scikit-learn's transformer classes, and add our own custom transformers. This might on first glance look as a tedious way to clean data. However, it will be very powerful later on. The transformer's parameters are actually hyperparameters in model selection. This means that a grid-search can be employed to evaluate several different strategies for i.e. imputation of missing values, cutoff thresholds for sparse features and so on and find the best preprocessing steps.\n",
    "\n",
    "sklearn doc:\n",
    "\n",
    "* http://scikit-learn.org/dev/modules/generated/sklearn.compose.ColumnTransformer.html\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#from category_encoders.hashing import HashingEncoder  # Use custom edits in local file instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary features\n",
    "\n",
    "For these, we will convert the values specified as True and False as per the dataset dictionary into 1.0 and 0.0 respectively. Furthermore, input errors are also being treated. In the end, these features will be of dtype float64, having {1.0, 0.0 and NaN} as values.\n",
    "\n",
    "For features that either have a value representing True or are empty (as specified in the dataset dictionary), all empty cells will be considered False. For features specifically denoting True and False values, these will be coded appropriately and empty cells set to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MAILCODE', 'NOEXCH', 'RECSWEEP', 'RECINHSE', 'RECP3', 'RECPGVG', 'AGEFLAG', 'HOMEOWNR', 'MAJOR', 'COLLECT1', 'BIBLE', 'CATLG', 'HOMEE', 'PETS', 'CDPLAY', 'STEREO', 'PCOWNERS', 'PHOTO', 'CRAFTS', 'FISHER', 'GARDENIN', 'BOATS', 'WALKER', 'KIDSTUFF', 'CARDS', 'PLATES', 'PEPSTRFL', 'TARGET_B', 'HPHONE_D', 'VETERANS']\n"
     ]
    }
   ],
   "source": [
    "print(dl.binary_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "binary_transformers = ColumnTransformer([\n",
    "    (\"binary_x_bl\",\n",
    "     BinaryFeatureRecode(value_map={'true': 'X', 'false': ' '}, correct_noisy=False),\n",
    "     ['PEPSTRFL', 'NOEXCH', 'MAJOR', 'RECINHSE', 'RECP3', 'RECPGVG', 'RECSWEEP']\n",
    "     ),\n",
    "    (\"binary_y_n\",\n",
    "     BinaryFeatureRecode(value_map={'true': 'Y', 'false': 'N'}, correct_noisy=False),\n",
    "     ['COLLECT1', 'VETERANS', 'BIBLE', 'CATLG', 'HOMEE', 'PETS', 'CDPLAY', 'STEREO',\n",
    "      'PCOWNERS', 'PHOTO', 'CRAFTS', 'FISHER', 'GARDENIN',  'BOATS', 'WALKER', 'KIDSTUFF',\n",
    "      'CARDS', 'PLATES']\n",
    "     ),\n",
    "    (\"binary_e_i\",\n",
    "     BinaryFeatureRecode(value_map={'true': \"E\", 'false': 'I'}, correct_noisy=False),\n",
    "     ['AGEFLAG']\n",
    "     ),\n",
    "    (\"binary_h_u\",\n",
    "     BinaryFeatureRecode(value_map={'true': \"H\", 'false': 'U'}, correct_noisy=False),\n",
    "     ['HOMEOWNR']),\n",
    "    (\"binary_b_bl\",\n",
    "     BinaryFeatureRecode(value_map={'true': 'B', 'false': ' '}, correct_noisy=False),\n",
    "     ['MAILCODE']\n",
    "     ),\n",
    "    (\"binary_1_0\",\n",
    "     BinaryFeatureRecode(value_map={'true': '1', 'false': '0'}, correct_noisy=False),\n",
    "     ['HPHONE_D', 'TARGET_B']\n",
    "     )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarys = binary_transformers.fit_transform(learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_feature_names = [n[n.find('__')+2:]\n",
    "                 for n in binary_transformers.get_feature_names()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarys = pd.DataFrame(data=binarys, columns=binary_feature_names,\n",
    "                     index=learning.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 95412 entries, 95515 to 185114\n",
      "Data columns (total 30 columns):\n",
      "PEPSTRFL    45269 non-null float64\n",
      "NOEXCH      95405 non-null float64\n",
      "MAJOR       294 non-null float64\n",
      "RECINHSE    6703 non-null float64\n",
      "RECP3       2017 non-null float64\n",
      "RECPGVG     114 non-null float64\n",
      "RECSWEEP    1617 non-null float64\n",
      "COLLECT1    5202 non-null float64\n",
      "VETERANS    10426 non-null float64\n",
      "BIBLE       8871 non-null float64\n",
      "CATLG       7865 non-null float64\n",
      "HOMEE       887 non-null float64\n",
      "PETS        14326 non-null float64\n",
      "CDPLAY      12254 non-null float64\n",
      "STEREO      12794 non-null float64\n",
      "PCOWNERS    10481 non-null float64\n",
      "PHOTO       4786 non-null float64\n",
      "CRAFTS      8176 non-null float64\n",
      "FISHER      7130 non-null float64\n",
      "GARDENIN    13402 non-null float64\n",
      "BOATS       2028 non-null float64\n",
      "WALKER      10501 non-null float64\n",
      "KIDSTUFF    1536 non-null float64\n",
      "CARDS       1041 non-null float64\n",
      "PLATES      560 non-null float64\n",
      "AGEFLAG     65864 non-null float64\n",
      "HOMEOWNR    73184 non-null float64\n",
      "MAILCODE    1399 non-null float64\n",
      "HPHONE_D    95412 non-null float64\n",
      "TARGET_B    95412 non-null float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 22.6 MB\n"
     ]
    }
   ],
   "source": [
    "binarys.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several features contain only very few actual feature values. These might get dropped by the sparsity transformer later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning[binary_feature_names] = binarys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dates\n",
    "\n",
    "There are several date features. ODATEDW is the date the record was added, DOB the birth date. ADATE_* and RDATE_* are from the promotion history. ADATE_* is the date of a mailing, RDATE_* the date the donation for the corresponding mailing was received. While these dates are not of particular interest (very low variance), the time it took to respond might be.\n",
    "Furthermore, there are the features MINRDATE, MAXRDATE, MAXADATE, FISTDATE, NEXTDATE and LASTDATE coming from the giving history file.\n",
    "\n",
    "Three different transformations are applied:\n",
    "\n",
    "1. ODATEDW, DOB: Years before 1997 -> membership duration, age\n",
    "2. Giving history features: Relative time in months to 1997/06/01\n",
    "3. For the promotion history, as specified above, the time for response in months\n",
    "\n",
    "There are redundant features which can be safely removed, as is shown below:\n",
    "\n",
    "1. FISTDATE and NEXTDATE are contained in TIMELAG, the number of months between first and second donation\n",
    "2. DOB, the date of birth, is contained in the feature AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ODATEDW', 'DOB', 'ADATE_2', 'ADATE_3', 'ADATE_4', 'ADATE_5', 'ADATE_6', 'ADATE_7', 'ADATE_8', 'ADATE_9', 'ADATE_10', 'ADATE_11', 'ADATE_12', 'ADATE_13', 'ADATE_14', 'ADATE_15', 'ADATE_16', 'ADATE_17', 'ADATE_18', 'ADATE_19', 'ADATE_20', 'ADATE_21', 'ADATE_22', 'ADATE_23', 'ADATE_24', 'RDATE_3', 'RDATE_4', 'RDATE_5', 'RDATE_6', 'RDATE_7', 'RDATE_8', 'RDATE_9', 'RDATE_10', 'RDATE_11', 'RDATE_12', 'RDATE_13', 'RDATE_14', 'RDATE_15', 'RDATE_16', 'RDATE_17', 'RDATE_18', 'RDATE_19', 'RDATE_20', 'RDATE_21', 'RDATE_22', 'RDATE_23', 'RDATE_24', 'LASTDATE', 'MINRDATE', 'MAXRDATE', 'FISTDATE', 'NEXTDATE', 'MAXADATE']\n"
     ]
    }
   ],
   "source": [
    "print(dl.date_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we transform the dates from the giving history. First, we create two dataframes with the sending dates of the mailings and the dates when the gift (donation) for these was received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "don_hist_transformer = ColumnTransformer([\n",
    "    (\"months_to_donation\",\n",
    "     MonthsToDonation(),\n",
    "     dl.promo_history_dates+dl.giving_history_dates\n",
    "     )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "donation_responses = don_hist_transformer.fit_transform(learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "don_hist_feature_names = [n[n.find('__')+2:]\n",
    "                 for n in don_hist_transformer.get_feature_names()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "donation_responses = pd.DataFrame(\n",
    "    donation_responses, index=learning.index, columns=don_hist_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning = learning.merge(donation_responses, on=learning.index.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time delta computation of the remaining features with either a specific reference or the date of the most recent mailing as a reference:\n",
    "\n",
    "* Time since last donation, minimum- and maximum donation and receiving most recent promotion\n",
    "* Delta between first and next donation\n",
    "* Age, years of membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "timedelta_transformer = ColumnTransformer([\n",
    "    (\"time_last_donation\", DeltaTime(unit='months'), ['LASTDATE','MINRDATE','MAXRDATE','MAXADATE']),\n",
    "    (\"delta_first_next\", DeltaTime(reference_date=learning.NEXTDATE), ['FISTDATE']),\n",
    "    (\"membership_years\", DeltaTime(unit='years'),['ODATEDW', 'DOB'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "timedeltas = timedelta_transformer.fit_transform(learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "timedelta_feature_names = [n[n.find('__')+2:]\n",
    "                 for n in timedelta_transformer.get_feature_names()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "timedeltas = pd.DataFrame(timedeltas, index=learning.index,columns=timedelta_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LASTDATE_DELTA_MONTHS', 'MINRDATE_DELTA_MONTHS',\n",
       "       'MAXRDATE_DELTA_MONTHS', 'MAXADATE_DELTA_MONTHS',\n",
       "       'FISTDATE_NEXTDATE_DELTA_MONTHS', 'ODATEDW_DELTA_YEARS',\n",
       "       'DOB_DELTA_YEARS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timedeltas.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning = learning.merge(timedeltas, on=learning.index.name)\n",
    "learning.drop(dl.date_features, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Studying redundance of DOB <-> AGE and \\[FISTDATE, NEXTDATE\\] <-> TIMELAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = pd.DataFrame([learning.AGE, timedeltas.DOB_DELTA_YEARS]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>DOB_DELTA_YEARS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONTROLN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [AGE, DOB_DELTA_YEARS]\n",
       "Index: []"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ages.loc[ages.AGE != ages.DOB_DELTA_YEARS,:].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = pd.DataFrame([learning.TIMELAG, timedeltas.FISTDATE_NEXTDATE_DELTA_MONTHS]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMELAG</th>\n",
       "      <th>FISTDATE_NEXTDATE_DELTA_MONTHS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONTROLN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [TIMELAG, FISTDATE_NEXTDATE_DELTA_MONTHS]\n",
       "Index: []"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lags.loc[lags.TIMELAG != lags.FISTDATE_NEXTDATE_DELTA_MONTHS,:].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformed feature DOB is represented in the feature AGE already. So we can drop DOB_DELTA_YEARS. TIMELAG already holds the difference in months between FISTDATE and NEXTDATE, so this delta can also be safely removed together with the original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.drop(['DOB_DELTA_YEARS', 'FISTDATE_NEXTDATE_DELTA_MONTHS'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories\n",
    "\n",
    "\n",
    "Some categories are already created on import of the data. Additionally, we will have to treat some special cases:\n",
    "\n",
    "* Multibyte features. These are features that group together several related nominal features. These are mainly the promotion history codes. Recency, Frequency and Amount as of a particular mailing are glued together in one feature. For RFA_2 and additionally MDMAUD, the major donor matrix, the features were already spread out by the supplier of the data. These two were dropped on import of the CSV file and their spread out features kept.\n",
    "\n",
    "* OSOURCE: It identifies the origin of the data for a particular record. However, it has so many levels that the feature space would get inflated heavily by one-hot encoding. For this feature, hasing is employed.\n",
    "\n",
    "* TCODE: Special treatment will also be necessary for the TCODE feature. It describes the title code (Ms., Hon., and so on) in an unfortunate integer coding ranging from 1e0 to 1e4. We will also use the hasing encoder for these features\n",
    "\n",
    "After having the categorical features ready, missing values are assigned their own category, 'missing'. Then, all non-hashed categorical features are one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STATE', 'PVASTATE', 'DOMAIN', 'CLUSTER', 'CHILD03', 'CHILD07',\n",
       "       'CHILD12', 'CHILD18', 'GENDER', 'WEALTH1', 'DATASRCE', 'SOLP3', 'SOLIH',\n",
       "       'WEALTH2', 'GEOCODE', 'LIFESRC', 'TARGET_D', 'RFA_2R', 'RFA_2F',\n",
       "       'RFA_2A', 'MDMAUD_R', 'MDMAUD_F', 'MDMAUD_A', 'GEOCODE2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning.select_dtypes(include=\"category\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treating multibyte features, OSOURCE and TCODE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OSOURCE', 'TCODE', 'RFA_3', 'RFA_4', 'RFA_5', 'RFA_6', 'RFA_7', 'RFA_8', 'RFA_9', 'RFA_10', 'RFA_11', 'RFA_12', 'RFA_13', 'RFA_14', 'RFA_15', 'RFA_16', 'RFA_17', 'RFA_18', 'RFA_19', 'RFA_20', 'RFA_21', 'RFA_22', 'RFA_23', 'RFA_24']\n"
     ]
    }
   ],
   "source": [
    "print(dl.nominal_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://booking.ai/dont-be-tricked-by-the-hashing-trick-192a6aae3087\n",
    "\n",
    "https://towardsdatascience.com/smarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159\n",
    "\n",
    "The hashing transformer hashes the nominal feature values into an 8 bit representation. If more than one feature is passed in, they all get encoded into the same 8 bits, therefore in effect reducing the dimensionality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_transformer = ColumnTransformer([\n",
    "    (\"hash_osource\", HashingEncoder(), ['OSOURCE'])\n",
    "])\n",
    "\n",
    "multibyte_transformer = ColumnTransformer([\n",
    "    (\"promotion_history_spreader\",\n",
    "     MultiByteExtract([\"R\", \"F\", \"A\"]),\n",
    "     dl.nominal_features[2:]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the transormations to all RFA_* features and the OSOURCE feature and extract the new feature names to build a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = hash_transformer.fit_transform(learning)\n",
    "feature_names_h = [n[n.find('__')+2:]\n",
    "                 for n in hash_transformer.get_feature_names()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "multibytes = multibyte_transformer.fit_transform(learning)\n",
    "feature_names_m = [n[n.find('__')+2:]\n",
    "                 for n in multibyte_transformer.get_feature_names()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge learning and the new nominal features, then drop the originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "multibytes = pd.DataFrame(data=multibytes, columns=feature_names_m,\n",
    "                   index=learning.index).astype(\"category\")\n",
    "learning = learning.merge(multibytes, on=learning.index.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = pd.DataFrame(data=hashes, columns=feature_names_h,\n",
    "                   index=learning.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning = learning.merge(hashes, on=learning.index.name)\n",
    "learning = learning.drop(dl.nominal_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: STATE\n",
      "Index(['AA', 'AE', 'AK', 'AL', 'AP', 'AR', 'AS', 'AZ', 'CA', 'CO', 'CT', 'DC',\n",
      "       'DE', 'FL', 'GA', 'GU', 'HI', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA',\n",
      "       'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH',\n",
      "       'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN',\n",
      "       'TX', 'UT', 'VA', 'VI', 'VT', 'WA', 'WI', 'WV', 'WY'],\n",
      "      dtype='object')\n",
      "Feature: PVASTATE\n",
      "Index(['E', 'P'], dtype='object')\n",
      "Feature: DOMAIN\n",
      "Index(['C1', 'C2', 'C3', 'R1', 'R2', 'R3', 'S1', 'S2', 'S3', 'T1', 'T2', 'T3',\n",
      "       'U1', 'U2', 'U3', 'U4'],\n",
      "      dtype='object')\n",
      "Feature: CLUSTER\n",
      "Index(['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12',\n",
      "       '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24',\n",
      "       '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36',\n",
      "       '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48',\n",
      "       '49', '50', '51', '52', '53'],\n",
      "      dtype='object')\n",
      "Feature: CHILD03\n",
      "Index(['B', 'F', 'M'], dtype='object')\n",
      "Feature: CHILD07\n",
      "Index(['B', 'F', 'M'], dtype='object')\n",
      "Feature: CHILD12\n",
      "Index(['B', 'F', 'M'], dtype='object')\n",
      "Feature: CHILD18\n",
      "Index(['B', 'F', 'M'], dtype='object')\n",
      "Feature: GENDER\n",
      "Index(['A', 'C', 'F', 'J', 'M', 'U'], dtype='object')\n",
      "Feature: WEALTH1\n",
      "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='object')\n",
      "Feature: DATASRCE\n",
      "Index(['1', '2', '3'], dtype='object')\n",
      "Feature: SOLP3\n",
      "Index(['00', '01', '02', '12'], dtype='object')\n",
      "Feature: SOLIH\n",
      "Index(['00', '01', '02', '03', '04', '06', '12'], dtype='object')\n",
      "Feature: WEALTH2\n",
      "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='object')\n",
      "Feature: GEOCODE\n",
      "Index(['01', '02', '03', '04', '05', '12', '14'], dtype='object')\n",
      "Feature: LIFESRC\n",
      "Index(['1', '2', '3'], dtype='object')\n",
      "Feature: TARGET_D\n",
      "Index(['0', '1', '10', '10.7', '100', '101', '102', '11', '12', '12.5', '13',\n",
      "       '13.92', '14', '15', '150', '16', '16.87', '17', '17.5', '18', '18.25',\n",
      "       '19', '2', '2.5', '20', '200', '21', '22', '23', '24', '25', '26', '27',\n",
      "       '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38',\n",
      "       '4', '4.5', '40', '41', '42', '43', '44', '44.21', '45', '46', '47',\n",
      "       '48', '5', '5.25', '50', '51', '53', '55', '6', '60', '7', '7.5', '75',\n",
      "       '8', '9', '95'],\n",
      "      dtype='object')\n",
      "Feature: RFA_2R\n",
      "Index(['L'], dtype='object')\n",
      "Feature: RFA_2F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_2A\n",
      "Index(['D', 'E', 'F', 'G'], dtype='object')\n",
      "Feature: MDMAUD_R\n",
      "Index(['C', 'D', 'I', 'L'], dtype='object')\n",
      "Feature: MDMAUD_F\n",
      "Index(['1', '2', '5'], dtype='object')\n",
      "Feature: MDMAUD_A\n",
      "Index(['C', 'L', 'M', 'T'], dtype='object')\n",
      "Feature: GEOCODE2\n",
      "Index(['A', 'B', 'C', 'D'], dtype='object')\n",
      "Feature: RFA_3R\n",
      "Index(['A', 'F', 'L', 'N', 'S'], dtype='object')\n",
      "Feature: RFA_3F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_3A\n",
      "Index(['B', 'C', 'D', 'E', 'F', 'G'], dtype='object')\n",
      "Feature: RFA_4R\n",
      "Index(['A', 'F', 'L', 'N', 'S'], dtype='object')\n",
      "Feature: RFA_4F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_4A\n",
      "Index(['B', 'C', 'D', 'E', 'F', 'G'], dtype='object')\n",
      "Feature: RFA_5R\n",
      "Index(['A', 'L', 'N', 'S'], dtype='object')\n",
      "Feature: RFA_5F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_5A\n",
      "Index(['D', 'E', 'F', 'G'], dtype='object')\n",
      "Feature: RFA_6R\n",
      "Index(['A', 'F', 'I', 'L', 'N', 'P', 'S', 'U'], dtype='object')\n",
      "Feature: RFA_6F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_6A\n",
      "Index(['A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='object')\n",
      "Feature: RFA_7R\n",
      "Index(['A', 'F', 'I', 'L', 'N', 'P', 'S', 'U'], dtype='object')\n",
      "Feature: RFA_7F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_7A\n",
      "Index(['A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='object')\n",
      "Feature: RFA_8R\n",
      "Index(['A', 'F', 'I', 'L', 'N', 'P', 'S', 'U'], dtype='object')\n",
      "Feature: RFA_8F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_8A\n",
      "Index(['A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='object')\n",
      "Feature: RFA_9R\n",
      "Index(['A', 'F', 'I', 'L', 'N', 'P', 'S', 'U'], dtype='object')\n",
      "Feature: RFA_9F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_9A\n",
      "Index(['A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='object')\n",
      "Feature: RFA_10R\n",
      "Index(['A', 'F', 'I', 'L', 'N', 'S'], dtype='object')\n",
      "Feature: RFA_10F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_10A\n",
      "Index(['B', 'C', 'D', 'E', 'F', 'G'], dtype='object')\n",
      "Feature: RFA_11R\n",
      "Index(['A', 'F', 'I', 'L', 'N', 'P', 'S'], dtype='object')\n",
      "Feature: RFA_11F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_11A\n",
      "Index(['A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='object')\n",
      "Feature: RFA_12R\n",
      "Index(['A', 'F', 'I', 'L', 'N', 'P', 'S', 'U'], dtype='object')\n",
      "Feature: RFA_12F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_12A\n",
      "Index(['A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='object')\n",
      "Feature: RFA_13R\n",
      "Index(['A', 'F', 'I', 'L', 'N', 'S', 'U'], dtype='object')\n",
      "Feature: RFA_13F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_13A\n",
      "Index(['B', 'C', 'D', 'E', 'F', 'G'], dtype='object')\n",
      "Feature: RFA_14R\n",
      "Index(['A', 'F', 'I', 'L', 'N', 'P', 'S', 'U'], dtype='object')\n",
      "Feature: RFA_14F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_14A\n",
      "Index(['A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='object')\n",
      "Feature: RFA_15R\n",
      "Index(['A', 'N', 'S', 'U'], dtype='object')\n",
      "Feature: RFA_15F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_15A\n",
      "Index(['D', 'E', 'F', 'G'], dtype='object')\n",
      "Feature: RFA_16R\n",
      "Index(['A', 'F', 'I', 'L', 'N', 'P', 'S', 'U'], dtype='object')\n",
      "Feature: RFA_16F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_16A\n",
      "Index(['A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='object')\n",
      "Feature: RFA_17R\n",
      "Index(['A', 'F', 'I', 'L', 'N', 'P', 'S', 'U'], dtype='object')\n",
      "Feature: RFA_17F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_17A\n",
      "Index(['A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='object')\n",
      "Feature: RFA_18R\n",
      "Index(['A', 'F', 'I', 'L', 'N', 'P', 'S', 'U'], dtype='object')\n",
      "Feature: RFA_18F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_18A\n",
      "Index(['A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='object')\n",
      "Feature: RFA_19R\n",
      "Index(['A', 'F', 'I', 'L', 'N', 'P', 'S', 'U'], dtype='object')\n",
      "Feature: RFA_19F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_19A\n",
      "Index(['A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='object')\n",
      "Feature: RFA_20R\n",
      "Index(['A', 'F', 'I', 'L', 'N', 'S', 'U'], dtype='object')\n",
      "Feature: RFA_20F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_20A\n",
      "Index(['C', 'D', 'E', 'F', 'G'], dtype='object')\n",
      "Feature: RFA_21R\n",
      "Index(['A', 'F', 'I', 'L', 'N', 'P', 'S'], dtype='object')\n",
      "Feature: RFA_21F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_21A\n",
      "Index(['A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='object')\n",
      "Feature: RFA_22R\n",
      "Index(['A', 'F', 'I', 'L', 'N', 'P', 'S', 'U'], dtype='object')\n",
      "Feature: RFA_22F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_22A\n",
      "Index(['A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='object')\n",
      "Feature: RFA_23R\n",
      "Index(['A', 'F', 'I', 'L', 'N', 'S', 'U'], dtype='object')\n",
      "Feature: RFA_23F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_23A\n",
      "Index(['B', 'C', 'D', 'E', 'F', 'G'], dtype='object')\n",
      "Feature: RFA_24R\n",
      "Index(['A', 'F', 'I', 'L', 'N', 'P', 'S', 'U'], dtype='object')\n",
      "Feature: RFA_24F\n",
      "Index(['1', '2', '3', '4'], dtype='object')\n",
      "Feature: RFA_24A\n",
      "Index(['A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for cat in learning.select_dtypes(include=\"category\").columns:\n",
    "    learning[cat] = learning[cat].cat.remove_unused_categories()\n",
    "    print(\"Feature: {}\\n{}\".format(cat, learning[cat].cat.categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinal features\n",
    "\n",
    "Several ordinal features are present. We need to ensure to encode the levels correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the order is obvious, no order has to be passed in (i.e. 0 < 1 < 2 < 3 < ... and alphabetical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ordered(feature):\n",
    "    try:\n",
    "        learning[feature] = learning[feature].cat.as_ordered()\n",
    "    except AttributeError as e:\n",
    "         learning[feature] = learning[feature].astype(\"category\").cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['WEALTH1','WEALTH2','INCOME']+list(learning.filter(regex=\"RFA_\\d{1,2}F\").columns)+list(learning.filter(regex=\"RFA_\\d{1,2}A\").columns):\n",
    "    make_ordered(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for x in X_trans:\n",
    "    print(learning[x].cat.ordered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a new level 'missing' to each category to encode NaN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cols = learning.select_dtypes(include=\"int64\").columns\n",
    "learning[int_cols] = learning[int_cols].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 95412 entries, 95515 to 185114\n",
      "Columns: 502 entries, STATE to OSOURCE_7\n",
      "dtypes: category(91), float64(411)\n",
      "memory usage: 308.2 MB\n"
     ]
    }
   ],
   "source": [
    "learning.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A look at the label (amount donated in US dollars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.barplot(x = [0,1], y = learning.groupby('TARGET_B')['TARGET_B'].count()/len(learning.index),\n",
    "                  palette=App.config(\"color_palette_binary\"));\n",
    "fig.set_xticklabels([\"No\", \"Yes\"]);\n",
    "plt.xlabel(\"Donated\");\n",
    "plt.ylabel(\"Percentage of examples\");\n",
    "save_fig(fig_id=\"label_ratio_binary\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.distplot(learning.loc[learning.TARGET_D > 0, ('TARGET_D')], bins=100, hist_kws={'alpha': 0.9}, color=App.config(\"color_palette\")[0])\n",
    "plt.ylabel(\"Percentage of donors\");\n",
    "save_fig('label_distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.loc[learning.TARGET_D > 0.0, 'TARGET_D'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The label is imbalanced, with roughly 95% / 5%\n",
    "* Most donations are below 20 dollars. The median is 13 \\$\n",
    "* Spikes are visible for 5, 10, 15, 20, 25, 50, 100 and 200 $\n",
    "* The distribution is right-skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the claim from the documentation that donations are positively correlated with the time since the last donation. We plot the duration since the last gift against the donation amount for the current campaign. The marker size indicates the total amount an example has donated so far.\n",
    "\n",
    "It is evident that from a lag of &geq; 15 months, donations increase indeed, and over the whole spectrum of amounts. We see a marked difference in 100- and 50 $ donations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='LASTDATE_DELTA_MONTHS',y='TARGET_D', size='RAMNTALL', alpha=0.6, data=learning.loc[learning.TARGET_D > 0,:],\n",
    "                palette=App.config(\"color_palette_binary\"))\n",
    "plt.xlabel(\"Months passed without a donation before the current donation\");\n",
    "plt.ylabel(\"Amount donated, $\");\n",
    "save_fig(fig_id=\"donations_vs_time_since_last\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Socio-economic environment and label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donations by living environment (C=City, R=Rural, S=Suburban, T=Town,U=Urban; lowest numbers represent highest socio-economic ranking). Major donors versus non-major donors.\n",
    "\n",
    "Surprisingly, one of the top donations came from a rural region of low socio-economic status. Major donors that donated this time are not present in the lowest socio-economic environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(y=\"TARGET_D\", x=\"DOMAIN\", hue='MAJOR',cut=0, data=learning.loc[learning.TARGET_D > 0,:],\n",
    "               palette=App.config(\"color_palette_binary\"))\n",
    "plt.xlabel(\"Living environment and socio-economic status\");\n",
    "plt.ylabel(\"Amount donated, $\");\n",
    "save_fig(fig_id=\"donations_vs_living_environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All-time donations by environment. The y- axis is in log scale. We see now that each socio-economic environment also harbours major donors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=sns.boxplot(y=\"RAMNTALL\", x=\"DOMAIN\", hue='MAJOR', data=learning,palette=App.config(\"color_palette_binary\"))\n",
    "fig.set_yscale('log')\n",
    "plt.xlabel(\"Living environment and socio-economic status\");\n",
    "plt.ylabel(\"Lifetime amount donated, $\");\n",
    "save_fig(fig_id=\"donations_vs_living_environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are so many features, we will plot those who have a significant correlation only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_all = learning.drop(['TARGET_B','TARGET_D'], axis=1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_all = np.zeros_like(corr_all, dtype=np.bool)\n",
    "mask_all[np.triu_indices_from(mask_all)] = True\n",
    "\n",
    "sns.heatmap(corr_all,\n",
    "            cmap=App.config(\"color_map_diverging\"), mask=mask_all, vmax=1.0, center = 0.0, square=True,\n",
    "            linewidths = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations between numerical features, excluding US census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exclude_census_numeric = learning[learning.columns.difference(dl.us_census_features)].select_dtypes(include=[\"float64\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exclude_census_corr = data_exclude_census_numeric[data_exclude_census_numeric.columns.difference(['TARGET_B','TARGET_D'])].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_census = np.zeros_like(data_exclude_census_corr, dtype=np.bool)\n",
    "mask_census[np.triu_indices_from(mask_census)] = True\n",
    "\n",
    "sns.heatmap(data_exclude_census_corr, mask=mask_census, cmap=App.config(\"color_map_diverging\"), vmax=1.0, center=0,\n",
    "            square=True, linewidths=.1, cbar_kws={\"shrink\": .5}, xticklabels=True,yticklabels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promotion history correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prom_hist_f = list(donation_responses.columns)+list(multibytes.columns)+dl.promo_history_summary\n",
    "promotion_history_features = learning.reindex(columns=prom_hist_f)\n",
    "prom_hist_corr = promotion_history_features[promotion_history_features.columns.difference(['TARGET_B','TARGET_D'])].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_promo = np.zeros_like(prom_hist_corr, dtype=np.bool)\n",
    "mask_promo[np.triu_indices_from(mask_promo)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "sns.heatmap(prom_hist_corr, mask=mask_promo, cmap=App.config(\"color_map_diverging\"), vmax=1.0, center=0,\n",
    "            square=True, linewidths=.3, cbar_kws={\"shrink\": .5}, xticklabels=True,yticklabels=True)\n",
    "save_fig(fig_id=\"correlations_promotion_giving_history\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giving history correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giving_hist_f = list(donation_responses.columns) + dl.giving_history + dl.giving_history_summary +['LASTDATE_DELTA_MONTHS', 'MINRDATE_DELTA_MONTHS',\n",
    "       'MAXRDATE_DELTA_MONTHS', 'MAXADATE_DELTA_MONTHS']\n",
    "giving_history_features = learning.loc[:,giving_hist_f]\n",
    "giving_corr = giving_history_features[giving_history_features.columns.difference(['TARGET_B','TARGET_D'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_giving = np.zeros_like(giving_corr, dtype=np.bool)\n",
    "mask_giving[np.triu_indices_from(mask_giving)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "sns.heatmap(giving_corr, mask=mask_giving, cmap=App.config(\"color_map_diverging\"), vmax=1.0, center=0,\n",
    "            square=True, linewidths=.1, cbar_kws={\"shrink\": .5}, xticklabels=True,yticklabels=True)\n",
    "save_fig(fig_id=\"correlations_giving_history\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puttting donors on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_donors_by_zip = learning[['ZIP', 'TARGET_B']].groupby('ZIP', as_index=False).agg('sum') # number of people who donated\n",
    "num_members_by_zip = learning[['ZIP', 'TARGET_B']].groupby('ZIP', as_index=False).agg('count') # number of people who are registered at that ZIP\n",
    "cum_donation_by_zip = learning[['ZIP', 'TARGET_D']].groupby('ZIP', as_index=False).agg('sum')\n",
    "zip_states = learning[['ZIP','STATE']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_zip = cum_donation_by_zip.merge(num_members_by_zip, on='ZIP').merge(zip_states, on='ZIP')\n",
    "data_by_zip.columns = [\"ZIP\", \"CumDonation\", \"MemberCount\", \"State\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_donation(row):\n",
    "    if row.CumDonation != 0.0:\n",
    "        return row.CumDonation/(1.0 if row.MemberCount == 0.0 else row.MemberCount)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "data_by_zip['RelDonation'] = data_by_zip.apply(rel_donation,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Here\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "\n",
    "def do_geo_query(q):\n",
    "    geolocator = Here(app_id=\"ZJBxigwxa1QPHlWrtWH6\", app_code=\"OJBun02aepkFbuHmYn1bOg\")\n",
    "    geocode = RateLimiter(geolocator.geocode, min_delay_seconds=0.01, max_retries=4)\n",
    "    try:\n",
    "        return geolocator.geocode(query=q, exactly_one=True)\n",
    "    except GeocoderTimedOut:\n",
    "        return do_geo_query(q)\n",
    "\n",
    "def get_loc(example):\n",
    "    if example.ZIP:\n",
    "        zip = str(int(example.ZIP)).rjust(5, '0')\n",
    "        q = {'postalcode': zip, 'state': example.State}\n",
    "        return do_geo_query(q)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def extract_coords(location):\n",
    "    return [location.latitude, location.longitude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "try:\n",
    "    zip_data = open(\"zip_data.pkl\", \"rb\")\n",
    "    locations = pickle.load(zip_data)\n",
    "    zip_data.close()\n",
    "except Exception as e:\n",
    "    locations = data_by_zip.progress_apply(get_loc, axis=1)\n",
    "    locations = pd.DataFrame(locations, columns=\"location\")\n",
    "    locations['ZIP'] = data_by_zip.ZIP\n",
    "    zip_data = open(\"zip_data.pkl\", \"wb\")\n",
    "    pickle.dump(locations, zip_data)\n",
    "    zip_data.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_zip = data_by_zip.merge(locations, on='ZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_zip.loc[:,'longitude'] = data_by_zip.location.apply(lambda l: l.longitude if l != None else None)\n",
    "data_by_zip.loc[:,'latitude'] = data_by_zip.location.apply(lambda l: l.latitude if l != None else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AA, AE and AP stand for armed services. ZIP codes don't work here, they point anywhere. Also, we only include locations where someone has actually donated by filtering on CumDonation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_zip1 = data_by_zip.loc[data_by_zip.State != ['AA','AE','AP'],:]\n",
    "data_by_zip2 = data_by_zip1.loc[data_by_zip1.CumDonation > 0.0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "import cartopy.feature as cfeature\n",
    "fig = plt.figure(figsize=(20,16))\n",
    "\n",
    "osm_terrain = cimgt.OSM()\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1, projection=osm_terrain.crs)\n",
    "\n",
    "ax.set_extent([-166, -65, 10, 65], crs=ccrs.PlateCarree())\n",
    "ax.add_image(osm_terrain, 6)\n",
    "\n",
    "lon = data_by_zip2.longitude\n",
    "lat = data_by_zip2.latitude\n",
    "mc = data_by_zip2.MemberCount\n",
    "cd = data_by_zip2.CumDonation\n",
    "rd = data_by_zip2.RelDonation\n",
    "\n",
    "data_by_zip2.plot(kind=\"scatter\",x=\"longitude\",y=\"latitude\",ax=ax,\n",
    "                  s=cd, c=rd, label=\"Cumulative Donations\",\n",
    "                  legend=True, alpha=0.5, cmap=App.config(\"color_map\"),\n",
    "                  subplots=True, colorbar=True, transform=ccrs.PlateCarree())\n",
    "            \n",
    "save_fig(fig_id=\"donations_geographical\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Most donations come from the urban areas, especially San Francisco, Los Angeles, Miami, Chicago and Detroit. To a lesser extent, cities like Houston, Dallas, Minneapolis, Atlanta, Tampa, Seattle and Phoenix can be made out.\n",
    "* Interestingly, the East Coast has not donated, despite featuring some large metropolitan areas like New York, Boston, or Washington"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = learning.select_dtypes(\"category\").copy()\n",
    "target = categories['TARGET_D']\n",
    "categories = categories.drop('TARGET_D', axis=1)\n",
    "#categories['TARGET_B'] = learning.TARGET_B.astype(\"category\")\n",
    "#categories['TARGET_D'] = learning.TARGET_D\n",
    "#categories_grouped = categories.groupby('TARGET_B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "sequence too large; cannot be greater than 32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-210-39e2954654e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lbfgs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'multinomial'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: sequence too large; cannot be greater than 32"
     ]
    }
   ],
   "source": [
    "lm = LogisticRegression(C=1e5, solver='lbfgs', multi_class='multinomial')\n",
    "lm.fit(np.ndarray(categories),y=np.ndarray(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>INCOME</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TARGET_D</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8646</td>\n",
       "      <td>12482</td>\n",
       "      <td>8135</td>\n",
       "      <td>12092</td>\n",
       "      <td>14639</td>\n",
       "      <td>7347</td>\n",
       "      <td>7045</td>\n",
       "      <td>70386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>92</td>\n",
       "      <td>136</td>\n",
       "      <td>92</td>\n",
       "      <td>122</td>\n",
       "      <td>133</td>\n",
       "      <td>66</td>\n",
       "      <td>79</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.92</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>37</td>\n",
       "      <td>72</td>\n",
       "      <td>41</td>\n",
       "      <td>84</td>\n",
       "      <td>112</td>\n",
       "      <td>64</td>\n",
       "      <td>56</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.87</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.25</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35</td>\n",
       "      <td>69</td>\n",
       "      <td>47</td>\n",
       "      <td>81</td>\n",
       "      <td>102</td>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "      <td>73</td>\n",
       "      <td>44</td>\n",
       "      <td>47</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53</td>\n",
       "      <td>83</td>\n",
       "      <td>47</td>\n",
       "      <td>73</td>\n",
       "      <td>84</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>8558</td>\n",
       "      <td>15451</td>\n",
       "      <td>13114</td>\n",
       "      <td>12732</td>\n",
       "      <td>7471</td>\n",
       "      <td>9022</td>\n",
       "      <td>7778</td>\n",
       "      <td>74126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "INCOME     1.0    2.0    3.0    4.0    5.0   6.0   7.0    All\n",
       "TARGET_D                                                     \n",
       "0         8646  12482   8135  12092  14639  7347  7045  70386\n",
       "1            0      1      0      1      1     0     0      3\n",
       "10          92    136     92    122    133    66    79    720\n",
       "10.7         0      0      0      0      1     0     0      1\n",
       "100          0      3      1      2      4     3     3     16\n",
       "11          10     19     10     18     19     9    13     98\n",
       "12          12     22     11     33     24    12     8    122\n",
       "12.5         0      0      0      0      6     2     2     10\n",
       "13           8      9      4      7     10     6     4     48\n",
       "13.92        0      1      0      0      0     0     0      1\n",
       "14           8      7     10     15      9     6     7     62\n",
       "15          37     72     41     84    112    64    56    466\n",
       "150          0      0      0      0      1     0     0      1\n",
       "16           7      9      2     11     17    12     5     63\n",
       "16.87        0      1      0      0      0     0     0      1\n",
       "17           7      6      5      9     14     6     6     53\n",
       "17.5         0      0      0      0      0     1     0      1\n",
       "18           3      4      1      6      9     4     6     33\n",
       "18.25        0      1      0      0      0     0     0      1\n",
       "19           0      1      2      6      6     2     3     20\n",
       "2            1      5      4      3      2     3     0     18\n",
       "2.5          0      0      0      1      0     0     0      1\n",
       "20          35     69     47     81    102    58    59    451\n",
       "200          1      0      0      0      1     0     0      2\n",
       "21           7     12      8     12     15    14     9     77\n",
       "22           0      3      5      1      3     2     2     16\n",
       "23           2      3      2      6     12     4     4     33\n",
       "24           1      2      1      1      2     0     2      9\n",
       "25          15     31     35     38     73    44    47    283\n",
       "26           0      3      1      5      3     5     6     23\n",
       "...        ...    ...    ...    ...    ...   ...   ...    ...\n",
       "34           0      0      0      1      0     0     0      1\n",
       "35           1      4      4      3      7     5     5     29\n",
       "36           2      0      1      1      1     2     1      8\n",
       "37           0      0      1      1      2     0     1      5\n",
       "38           0      1      0      1      1     0     1      4\n",
       "4            3     17     11      7     13     3     4     58\n",
       "4.5          0      0      0      0      1     0     0      1\n",
       "40           1      6      3      1      7     4     2     24\n",
       "41           0      0      0      1      0     0     1      2\n",
       "42           0      0      0      0      1     0     0      1\n",
       "43           0      0      0      0      0     1     0      1\n",
       "44           0      1      0      0      1     0     0      2\n",
       "45           0      0      1      2      1     0     1      5\n",
       "46           0      1      0      0      0     0     0      1\n",
       "47           0      0      0      2      0     0     0      2\n",
       "48           0      0      0      0      1     0     0      1\n",
       "5           53     83     47     73     84    28    22    390\n",
       "50           6      3      6     11     12     6     8     52\n",
       "51           0      0      0      2      0     0     0      2\n",
       "53           0      1      0      0      0     0     1      2\n",
       "55           0      0      0      0      0     1     0      1\n",
       "6           13     22     11     11     17    12     9     95\n",
       "60           0      0      0      0      1     1     0      2\n",
       "7           11     16     16     18     13     9    10     93\n",
       "7.5          0      0      0      0      1     0     0      1\n",
       "75           0      0      0      0      2     2     2      6\n",
       "8           11     15     11     12     21     7    13     90\n",
       "9            4      9      8      9     17     6     4     57\n",
       "95           0      0      0      1      0     0     0      1\n",
       "All       8558  15451  13114  12732   7471  9022  7778  74126\n",
       "\n",
       "[68 rows x 8 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(categories.TARGET_D,[categories.INCOME],margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The US census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = learning[dl.us_census_features]\n",
    "census_corr = census.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(census_corr, dtype=np.binary)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "sns.heatmap(census_corr, mask=mask, cmap=cmap, vmax=1.0, center=0,\n",
    "            square=True, linewidths=.2, cbar_kws={\"shrink\": .5})\n",
    "save_fig(fig_id=\"correlation_census\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census.select_dtypes(include=\"int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Income, Wealth and donations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_targ = sns.violinplot(x=\"INCOME\", y=\"TARGET_D\", data=learning.loc[learning.TARGET_D > 0.0, [\"INCOME\",\"TARGET_D\"]])\n",
    "inc_targ.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weal1_targ = sns.violinplot(x=\"WEALTH1\", y=\"TARGET_D\", data=learning.loc[learning.TARGET_D > 0.0, [\"WEALTH1\",\"TARGET_D\"]])\n",
    "weal1_targ.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weal2_targ = sns.violinplot(x=\"WEALTH2\", y=\"TARGET_D\", data=learning.loc[learning.TARGET_D > 0.0, [\"WEALTH2\",\"TARGET_D\"]])\n",
    "weal2_targ.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"WEALTH2\", y=\"TARGET_D\", hue=\"MAJOR\",\n",
    "            kind=\"violin\", inner=\"stick\", split=True, data=learning.loc[learning.TARGET_D > 0.0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"CLUSTER\", y=\"TARGET_D\", kind=\"box\", data=learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(learning.loc[learning.TARGET_D > 0.0,\n",
    "                          'TARGET_D'], bins=50, kde=False, rug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.select_dtypes(include=np.float).hist(bins=50, figsize=(50, 50))\n",
    "plt.show()\n",
    "save_fig(\"float_feature_histograms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some promising fetures and their impact on the label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = learning.dropna(axis=1)\n",
    "y = X['TARGET_D'].values\n",
    "X = X.drop(['TARGET_B','TARGET_D'],axis=1)\n",
    "cats = X.select_dtypes(include='category').columns\n",
    "dummies = pd.get_dummies(X[cats])\n",
    "X = X.drop(cats, axis=1)\n",
    "X = X.merge(dummies,on=X.index).dropna().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.55150e+04, 6.10810e+04, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [1.48535e+05, 9.13260e+04, 1.60000e+01, ..., 0.00000e+00,\n",
       "        0.00000e+00, 1.00000e+00],\n",
       "       [1.50780e+04, 2.70170e+04, 2.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       ...,\n",
       "       [1.89641e+05, 4.89100e+04, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [4.69300e+03, 9.13200e+04, 0.00000e+00, ..., 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00],\n",
       "       [1.85114e+05, 2.84090e+04, 3.00000e+00, ..., 0.00000e+00,\n",
       "        0.00000e+00, 1.00000e+00]])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be str, not ValueError",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\boruta\\boruta_py.py\u001b[0m in \u001b[0;36m_get_imp\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_y_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_validate_y_class_weight\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    501\u001b[0m                                      \u001b[1;34m'\"balanced\" and \"balanced_subsample\". Given \"%s\".'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m                                      % self.class_weight)\n\u001b[0m\u001b[0;32m    503\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\". Given \"auto\".",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-240-cd039e616ba9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# find all relevant features - 5 features should be selected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mfeat_selector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# check selected features - first 5 features are selected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\boruta\\boruta_py.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    199\u001b[0m         \"\"\"\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweak\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\boruta\\boruta_py.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m             \u001b[1;31m# add shadow attributes, shuffle them and train estimator, get imps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m             \u001b[0mcur_imp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_shadows_get_imps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_reg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[1;31m# get the threshold of shadow importances we will use for rejection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\boruta\\boruta_py.py\u001b[0m in \u001b[0;36m_add_shadows_get_imps\u001b[1;34m(self, X, y, dec_reg)\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[0mx_sha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_shuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_sha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m         \u001b[1;31m# get importance of the merged matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m         \u001b[0mimp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_imp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_cur\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_sha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m         \u001b[1;31m# separate importances of real and shadow features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[0mimp_sha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_cur_w\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\boruta\\boruta_py.py\u001b[0m in \u001b[0;36m_get_imp\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m             raise ValueError('Please check your X and y variable. The provided'\n\u001b[1;32m--> 383\u001b[1;33m                              'estimator cannot be fitted to your data.\\n' + e)\n\u001b[0m\u001b[0;32m    384\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[0mimp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: must be str, not ValueError"
     ]
    }
   ],
   "source": [
    "# define random forest classifier, with utilising all cores and\n",
    "# sampling in proportion to y labels\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='auto', max_depth=5)\n",
    "\n",
    "# define Boruta feature selection method\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=1)\n",
    "\n",
    "# find all relevant features - 5 features should be selected\n",
    "feat_selector.fit(X, y)\n",
    "\n",
    "# check selected features - first 5 features are selected\n",
    "feat_selector.support_\n",
    "\n",
    "# check ranking of features\n",
    "feat_selector.ranking_\n",
    "\n",
    "# call transform() on X to filter it down to selected features\n",
    "X_filtered = feat_selector.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "A first look at important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from kdd98.transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = learning.drop([\"TARGET_B\", \"TARGET_D\", \"TCODE\"], axis=1)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.select_dtypes(include=\"category\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"one_hot\",  OneHotEncoder(impute_missing=True,use_cat_names=True,return_df=True))\n",
    "])\n",
    "\n",
    "categories_transformer = ColumnTransformer([\n",
    "    (\"cat_encoder\",\n",
    "     cat_pipe,\n",
    "     list(X.select_dtypes(include=\"category\").columns))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = categories_transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(categories_transformer.named_transformers_.cat_encoder.named_steps.one_hot.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = pd.DataFrame(cats, columns = list(categories_transformer.named_transformers_.cat_encoder.named_steps.one_hot.get_feature_names()), index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.merge(cats, on=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(X.select_dtypes(include=\"category\").columns,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centered = X - X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centered = X_centered.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centered[X.select_dtypes(include=\"object\").columns] = X_centered[X.select_dtypes(include=\"object\").columns].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_centered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA()\n",
    "pca.fit(X_centered,)\n",
    "result = pd.DataFrame(pca.transform(X_centered), columns=[\n",
    "                      \"PCA%i\" % i for i in range(n_comp)], index=X.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
